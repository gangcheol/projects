[
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html",
    "title": "01. model tuning & save",
    "section": "",
    "text": "1 모델링 결과 XGB 모델을 적합했을 경우 가장 예측 성능이 좋았음\n2 Hyperparameter tuning 기법과 Selection 기법을 사용해 최종 모델링 수행\n\nHyperparameter Tuning: AI 모델 학습시 매개변수를 조정하여 최상의 성능을 발휘하는 매개변수를 찾는 기법\nFeature Selection: 모델링 시 raw data의 562개나 되는 모든 feature를 사용하는 것은 computing power와 memory 측면에서 매우 비효율적이기 때문에 결과 예측에 영향도가 높은 중요 feature만 선택하여 자원을 절약하고 모델의 성능을 높이는 기법",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "01. model tuning & save"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#라이브러리-호출",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#라이브러리-호출",
    "title": "01. model tuning & save",
    "section": "(1) 라이브러리 호출",
    "text": "(1) 라이브러리 호출\n\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "01. model tuning & save"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#xy-데이터-나누기",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#xy-데이터-나누기",
    "title": "01. model tuning & save",
    "section": "(2) X,y 데이터 나누기",
    "text": "(2) X,y 데이터 나누기\n\ntarget = \"Activity\"\n\nx = data.drop(target, axis = 1)\ny = data[target]",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "01. model tuning & save"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#encoding",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#encoding",
    "title": "01. model tuning & save",
    "section": "(3) Encoding",
    "text": "(3) Encoding\n\ndic = {'STANDING':0, 'SITTING':1, 'LAYING':2, 'WALKING':3, 'WALKING_UPSTAIRS':4, 'WALKING_DOWNSTAIRS':5}\ny_map = [dic[i] for i in y]\ny_map[:5]\n\n[0, 2, 0, 3, 5]",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "01. model tuning & save"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#train-test-data-분리",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#train-test-data-분리",
    "title": "01. model tuning & save",
    "section": "(4) train, test data 분리",
    "text": "(4) train, test data 분리\n\nx_train, x_val, y_train, y_val = train_test_split(x, y_map, random_state = 2023, test_size = 0.3)",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "01. model tuning & save"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#최적의-hyperparameter-찾기",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#최적의-hyperparameter-찾기",
    "title": "01. model tuning & save",
    "section": "(5) 최적의 Hyperparameter 찾기",
    "text": "(5) 최적의 Hyperparameter 찾기\n\nparams = {'learning_rate': [0.1, 0.2, 0.3], 'max_depth': [2, 3, 4]}\nxgb_model = XGBClassifier(random_state = 2023 )\n\nhpt_xgb_model = GridSearchCV(estimator= xgb_model , param_grid= params, cv=3, verbose=2)\n\nhpt_xgb_model.fit(x_train, y_train)\n\nhpt_xgb_pred = hpt_xgb_model.predict(x_val)\n\nFitting 3 folds for each of 9 candidates, totalling 27 fits\n[CV] END .....................learning_rate=0.1, max_depth=2; total time=   6.6s\n[CV] END .....................learning_rate=0.1, max_depth=2; total time=   6.8s\n[CV] END .....................learning_rate=0.1, max_depth=2; total time=   6.8s\n[CV] END .....................learning_rate=0.1, max_depth=3; total time=   9.1s\n[CV] END .....................learning_rate=0.1, max_depth=3; total time=   9.3s\n[CV] END .....................learning_rate=0.1, max_depth=3; total time=   9.5s\n[CV] END .....................learning_rate=0.1, max_depth=4; total time=  11.8s\n[CV] END .....................learning_rate=0.1, max_depth=4; total time=  11.9s\n[CV] END .....................learning_rate=0.1, max_depth=4; total time=  12.2s\n[CV] END .....................learning_rate=0.2, max_depth=2; total time=   7.2s\n[CV] END .....................learning_rate=0.2, max_depth=2; total time=   7.4s\n[CV] END .....................learning_rate=0.2, max_depth=2; total time=   7.3s\n[CV] END .....................learning_rate=0.2, max_depth=3; total time=   8.8s\n[CV] END .....................learning_rate=0.2, max_depth=3; total time=   8.8s\n[CV] END .....................learning_rate=0.2, max_depth=3; total time=   9.4s\n[CV] END .....................learning_rate=0.2, max_depth=4; total time=  10.3s\n[CV] END .....................learning_rate=0.2, max_depth=4; total time=  10.1s\n[CV] END .....................learning_rate=0.2, max_depth=4; total time=   9.8s\n[CV] END .....................learning_rate=0.3, max_depth=2; total time=   7.1s\n[CV] END .....................learning_rate=0.3, max_depth=2; total time=   6.8s\n[CV] END .....................learning_rate=0.3, max_depth=2; total time=   6.9s\n[CV] END .....................learning_rate=0.3, max_depth=3; total time=   8.0s\n[CV] END .....................learning_rate=0.3, max_depth=3; total time=   8.0s\n[CV] END .....................learning_rate=0.3, max_depth=3; total time=   7.9s\n[CV] END .....................learning_rate=0.3, max_depth=4; total time=   8.6s\n[CV] END .....................learning_rate=0.3, max_depth=4; total time=   8.6s\n[CV] END .....................learning_rate=0.3, max_depth=4; total time=   8.9s",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "01. model tuning & save"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#결과-확인-및-저장",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#결과-확인-및-저장",
    "title": "01. model tuning & save",
    "section": "(6) 결과 확인 및 저장",
    "text": "(6) 결과 확인 및 저장\n- 최적의 파라미터 확인\n\nparams = hpt_xgb_model.best_params_\nparams\n\n{'learning_rate': 0.3, 'max_depth': 2}\n\n\n- 정확도 확인\n\naccuracy_score(y_val,hpt_xgb_pred)\n\n0.9920679886685553\n\n\n\nhpt_xgb_model = XGBClassifier(learning_rate=0.3, max_depth = 2,random_state=2023)\nhpt_xgb_model.fit(x_train,y_train)\nhpt_xgb_pred = hpt_xgb_model.predict(x_val)\nhpt_xgb_pred\n\narray([3, 0, 2, ..., 3, 3, 2], dtype=int64)\n\n\n\nresult.loc[5] = [\"hpt_xgb\", \"train\", \n                 accuracy_score(y_val, hpt_xgb_pred), \n                 f1_score(y_val, hpt_xgb_pred, average = \"macro\")]\nresult\n\n\n\n\n\n\n\n\nmodel_name\nvalid_data\naccuracy_score\nF1_score\n\n\n\n\n0\nlr\ntrain\n0.984136\n0.985601\n\n\n1\nknn\ntrain\n0.954674\n0.958345\n\n\n2\ngbc\ntrain\n0.981870\n0.983141\n\n\n3\nxgb\ntrain\n0.990368\n0.991178\n\n\n5\nhpt_xgb\ntrain\n0.992068\n0.992707",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "01. model tuning & save"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#변수-중요도-산출",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#변수-중요도-산출",
    "title": "01. model tuning & save",
    "section": "(1) 변수 중요도 산출",
    "text": "(1) 변수 중요도 산출\n\nimp = hpt_xgb_model.feature_importances_\nf_name = hpt_xgb_model.feature_names_in_\n\n\nimportance_sort = pd.DataFrame({\"feature_name\" : f_name, \n                                \"feature_importance\" : imp})\nimportance_sort.head()\n\n\n\n\n\n\n\n\nfeature_name\nfeature_importance\n\n\n\n\n0\ntBodyAcc-mean()-X\n0.000000\n\n\n1\ntBodyAcc-mean()-Y\n0.000721\n\n\n2\ntBodyAcc-mean()-Z\n0.000000\n\n\n3\ntBodyAcc-std()-X\n0.000366\n\n\n4\ntBodyAcc-std()-Y\n0.000000\n\n\n\n\n\n\n\n\nimportance_sort.sort_values(\"feature_importance\", ascending = False, inplace = True)\nimportance_sort.head()\n\n\n\n\n\n\n\n\nfeature_name\nfeature_importance\n\n\n\n\n558\nangle(X,gravityMean)\n0.114671\n\n\n201\ntBodyAccMag-std()\n0.101686\n\n\n296\nfBodyAcc-skewness()-X\n0.065176\n\n\n503\nfBodyAccMag-std()\n0.042554\n\n\n73\ntGravityAcc-arCoeff()-Z,1\n0.040255\n\n\n\n\n\n\n\n\nimportance_sort.reset_index(drop = True, inplace = True)\n#importance_sort",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "01. model tuning & save"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#중요-feature-150개-선정",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#중요-feature-150개-선정",
    "title": "01. model tuning & save",
    "section": "(2) 중요 feature 150개 선정",
    "text": "(2) 중요 feature 150개 선정\n\nimportance_150 = importance_sort[\"feature_name\"][:150]\nimportance_150.head()\n\n0         angle(X,gravityMean)\n1            tBodyAccMag-std()\n2        fBodyAcc-skewness()-X\n3            fBodyAccMag-std()\n4    tGravityAcc-arCoeff()-Z,1\nName: feature_name, dtype: object\n\n\n\nx_train_150 = x_train[importance_150]\nx_val_150 = x_val[importance_150]\n\n\na. 모델링\n\nhpt_xgb_150_model = XGBClassifier(params, random_state = 2023)\nhpt_xgb_150_model.fit(x_train_150,y_train)\nhpt_xgb_150_pred = hpt_xgb_150_model.predict(x_val_150)\nhpt_xgb_150_pred\n\nC:\\Users\\rkdcj\\anaconda3\\envs\\dx\\Lib\\site-packages\\xgboost\\core.py:726: FutureWarning:\n\nPass `objective` as keyword args.\n\n\n\narray([3, 0, 2, ..., 3, 3, 2], dtype=int64)\n\n\n\n\nb. 예측 성능 결과 저장\n\nresult.loc[7] = [\"hpt_xgb_150\", \"train\", \n             accuracy_score(y_val,hpt_xgb_150_pred),\n             f1_score(y_val, hpt_xgb_150_pred, average = \"macro\")]\n\n\nresult\n\n\n\n\n\n\n\n\nmodel_name\nvalid_data\naccuracy_score\nF1_score\n\n\n\n\n0\nlr\ntrain\n0.984136\n0.985601\n\n\n1\nknn\ntrain\n0.954674\n0.958345\n\n\n2\ngbc\ntrain\n0.981870\n0.983141\n\n\n3\nxgb\ntrain\n0.990368\n0.991178\n\n\n5\nhpt_xgb\ntrain\n0.992068\n0.992707\n\n\n7\nhpt_xgb_150\ntrain\n0.989235\n0.989286",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "01. model tuning & save"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#중요-feature-50개-선정",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#중요-feature-50개-선정",
    "title": "01. model tuning & save",
    "section": "(3) 중요 feature 50개 선정",
    "text": "(3) 중요 feature 50개 선정\n\nimportance_50 = importance_150[:50]\nimportance_50.head()\n\n0         angle(X,gravityMean)\n1            tBodyAccMag-std()\n2        fBodyAcc-skewness()-X\n3            fBodyAccMag-std()\n4    tGravityAcc-arCoeff()-Z,1\nName: feature_name, dtype: object\n\n\n\na. 모델링\n\nx_train_50 = x_train[importance_50]\nx_val_50 = x_val[importance_50]\n\n\nhpt_xgb_50_model = XGBClassifier(params, random_stat = 2023)\nhpt_xgb_50_model.fit(x_train_50, y_train)\nhpt_xgb_50_pred = hpt_xgb_50_model.predict(x_val_50)\nhpt_xgb_50_pred\n\nC:\\Users\\rkdcj\\anaconda3\\envs\\dx\\Lib\\site-packages\\xgboost\\core.py:726: FutureWarning:\n\nPass `objective` as keyword args.\n\nC:\\Users\\rkdcj\\anaconda3\\envs\\dx\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning:\n\n[17:47:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \nParameters: { \"random_stat\" } are not used.\n\n\n\n\narray([3, 0, 2, ..., 3, 3, 2], dtype=int64)\n\n\n\n\nb. 예측 성능 결과 저장\n\nresult.loc[8] = [\"hpt_xgb_50\", \"train\", \n             accuracy_score(y_val,hpt_xgb_50_pred),\n             f1_score(y_val, hpt_xgb_50_pred, average = \"macro\")]\n\n\nresult\n\n\n\n\n\n\n\n\nmodel_name\nvalid_data\naccuracy_score\nF1_score\n\n\n\n\n0\nlr\ntrain\n0.984136\n0.985601\n\n\n1\nknn\ntrain\n0.954674\n0.958345\n\n\n2\ngbc\ntrain\n0.981870\n0.983141\n\n\n3\nxgb\ntrain\n0.990368\n0.991178\n\n\n5\nhpt_xgb\ntrain\n0.992068\n0.992707\n\n\n7\nhpt_xgb_150\ntrain\n0.989235\n0.989286\n\n\n8\nhpt_xgb_50\ntrain\n0.988102\n0.988090",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "01. model tuning & save"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#결과-시각화",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#결과-시각화",
    "title": "01. model tuning & save",
    "section": "(4) 결과 시각화",
    "text": "(4) 결과 시각화\n\nresult.melt(id_vars = [\"model_name\"], \n            value_vars= [\"accuracy_score\", \"F1_score\"])\n\n\n\n\n\n\n\n\nmodel_name\nvariable\nvalue\n\n\n\n\n0\nlr\naccuracy_score\n0.984136\n\n\n1\nknn\naccuracy_score\n0.954674\n\n\n2\ngbc\naccuracy_score\n0.981870\n\n\n3\nxgb\naccuracy_score\n0.990368\n\n\n4\nhpt_xgb\naccuracy_score\n0.992068\n\n\n5\nhpt_xgb_150\naccuracy_score\n0.989235\n\n\n6\nhpt_xgb_50\naccuracy_score\n0.988102\n\n\n7\nlr\nF1_score\n0.985601\n\n\n8\nknn\nF1_score\n0.958345\n\n\n9\ngbc\nF1_score\n0.983141\n\n\n10\nxgb\nF1_score\n0.991178\n\n\n11\nhpt_xgb\nF1_score\n0.992707\n\n\n12\nhpt_xgb_150\nF1_score\n0.989286\n\n\n13\nhpt_xgb_50\nF1_score\n0.988090\n\n\n\n\n\n\n\n\nfig = result.melt(id_vars = [\"model_name\"], \n            value_vars= [\"accuracy_score\", \"F1_score\"]).\\\n                plot(x = \"variable\", y = \"value\", \n                     color = \"variable\", kind = \"bar\", \n                     backend = \"plotly\", facet_col = \"model_name\", facet_col_wrap = 4,\n                     width = 1200, height = 800)\n\nfig.update_yaxes(range = (0.95, 1.0))",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "01. model tuning & save"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#model-save",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#model-save",
    "title": "01. model tuning & save",
    "section": "(5) model save",
    "text": "(5) model save\n- 최적의 성능을 보인 모델저장\n\nhpt_xgb 모델저장\n\n\nimport joblib\n\njoblib.dump(hpt_xgb_model, \"hpt_xgb_top_model.pkl\")\n\n['hpt_xgb_top_model.pkl']\n\n\n\n저장한 모델 로드\n\n\nfinal_model = joblib.load(\"hpt_xgb_top_model.pkl\")\n\n\n예측결과 저장\n\n\nfinal_pred = final_model.predict(x_val)\n\n\ndic.items()\n\ndict_items([('STANDING', 0), ('SITTING', 1), ('LAYING', 2), ('WALKING', 3), ('WALKING_UPSTAIRS', 4), ('WALKING_DOWNSTAIRS', 5)])\n\n\n\ndic_reverse = {j : i for i,j in dic.items()}\n\n\npd.Series(final_pred).map(dic_reverse).to_csv(\"final_predict.csv\", index = False)",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "01. model tuning & save"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Apple/2023-09-26-01. modeling.html",
    "href": "posts/mini projects/Fine Apple/2023-09-26-01. modeling.html",
    "title": "01. modeling",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\nimport os\nfrom sklearn.metrics import *\nfrom sklearn.model_selection import train_test_split\n\n\nplt.rc(\"font\", family = \"Malgun Gothic\")\nsns.set(font=\"Malgun Gothic\", \nrc={\"axes.unicode_minus\":False}, style='white')\n\n\ndata = pd.read_csv('customers_seg.csv', encoding = \"CP949\")\ndata.set_index(\"CID\", inplace = True)\ndata.head()\n\n\n\n\n\n\n\n\nAGE\n등록(계/피)\n고용상태\n성별\nWillingness to pay/Stay\n갱신\n상품타입\n교육수준\n소득\n지역\n결혼여부\n월 납입액\nVOC\n타 상품 보유 현황\n온라인방문빈도\n갱신인센티브\n판매채널\n총지불금액\n자동차\n거주지사이즈\n\n\nCID\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n3\n피보험자\n무직\n1\n2.616381\n0\n기본\n대학졸업\n0\n도시근교\n미혼\n80\n0\n1\n자주방문\n없음\n자사영업\n631000\n일반세단\n소\n\n\n2\n1\n계약자\n고용\n0\n6.352530\n0\n기본\n고졸이하\n102887400\n시골\n미혼\n80\n1\n4이상\n비방문\n포인트\n인터넷\n54000\n일반세단\n중\n\n\n3\n2\n계약자\n휴직\n0\n4.974354\n0\n기본\n대학졸업\n22159500\n도시근교\n기혼\n60\n0\n4이상\n비방문\n할인\n자사영업\n362000\n일반세단\n중\n\n\n4\n5\n계약자\n고용\n1\n13.480284\n0\n고급\n고졸이하\n51562500\n도시근교\n기혼\n110\n0\n2\n비방문\n할인\n자사영업\n1264000\n컴팩트카\n대\n\n\n5\n4\n계약자\n고용\n0\n9.776436\n0\n기본\n석사\n26820200\n도시근교\n기혼\n120\n0\n3\n비방문\n없음\n대리점\n947000\nSUV\n중",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Apple",
      "01. modeling"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Apple/2023-09-26-01. modeling.html#z-score-기반-이상치-처리",
    "href": "posts/mini projects/Fine Apple/2023-09-26-01. modeling.html#z-score-기반-이상치-처리",
    "title": "01. modeling",
    "section": "Z-score 기반 이상치 처리",
    "text": "Z-score 기반 이상치 처리\n\\[Z_{score} = \\frac {X - \\bar {X}}{sd(X)}\\]\n\n(1) 수치형 변수 분포 확인\n-&gt; 수치형 변수는 ‘AGE’,‘WTP’,‘소득’,‘월 납입액’,’총지불금액’으로 총 5개  * 단, AGE의 경우 기본적인 정보라서 이상치가 없을 것으로 제외  * WTP(Willingness to pay/Stay)의 경우, 기업에서 사전 정의/개발된 지표의 값 이므로 이상치 처리 대상에서 제외하고 진행  결론적으로, ‘소득’, ‘월납입액’, ‘총 지불 금액’ 3개의 항목만 이상치 처리\n\nfig = data_choice.melt(value_vars = [\"월 납입액\", \"소득\", \"총지불금액\"],\n                 var_name = \"var\").plot(y = \"value\", color=\"var\", kind = \"box\",\n                                       backend = \"plotly\",facet_col= \"var\")\n\nfig.update_yaxes(matches = None)\nfig.update_xaxes(matches = None)\n\n                                                \n\n\n\n\n(2) 수치형 변수 이상치 처리\n\nimport scipy.stats as spst\n\nz_list = ['소득','월 납입액','총지불금액']\n\nz_df = data_choice[z_list].apply(spst.zscore, axis = 0)\nz_df.columns = [i + \"_z\" for i in z_list]\n\ndata_choice = pd.concat([data_choice, z_df],axis=1)\n\n\n\n(3) 이상치 검토\nz-score가 3이상이거나 -3 이하이면 이상치로 검토\n\n+ 이상치의 최소값들을 찾기\n\n\n월 납입액 이상치 검토\n\nout = lambda x : True if abs(x)&gt;=3 else False\n\na = data_choice[\"월 납입액_z\"].map(out)\na1 = data_choice[\"월 납입액\"][a]\na2 = min(a1)\na2\n\n230\n\n\n- 위 단계를 한번에\n\nmin([j for i,j in zip(data_choice[\"월 납입액_z\"],data_choice[\"월 납입액\"]) if abs(i)&gt;=3])\n\n230\n\n\n\n\n소득 변수 이상치 검토\n\na = data_choice[\"소득_z\"].map(out)\n\na1 = data_choice[\"소득\"][a]\na1\n\nSeries([], Name: 소득, dtype: int64)\n\n\n\n\n총 지불액 이상치 검토\n\na = data_choice[\"총지불금액_z\"].map(out)\n\na1 = data_choice[\"총지불금액\"][a]\n\na2 = np.min(a1)\n\na2\n\n1612000\n\n\n\n\n전체 확인\n\nprint(\"소득 이상치 최소값(기준) : \",min([j if abs(i)&gt;=3 else np.nan for i,j in zip(data_choice[\"소득_z\"],data_choice[\"소득\"])]) )\nprint(\"월 납입액 이상치 최소값(기준) : \",min([j for i,j in zip(data_choice[\"월 납입액_z\"],data_choice[\"월 납입액\"]) if abs(i)&gt;=3])  )\nprint(\"총 지불 금액 이상치 최소값(기준) : \", min([j for i,j in zip(data_choice[\"총지불금액_z\"],data_choice[\"총지불금액\"]) if abs(i)&gt;=3 ]))\n\n소득 이상치 최소값(기준) :  nan\n월 납입액 이상치 최소값(기준) :  230\n총 지불 금액 이상치 최소값(기준) :  1612000\n\n\n\n\n\n(4) 이상치 대체\n\n월 납입액 이상치 대체\n\nm1 = min([j for i,j in zip(data_choice[\"월 납입액_z\"],data_choice[\"월 납입액\"]) if abs(i)&gt;=3])\n\ndata_choice[\"월 납입액_z\"] = [m1 if abs(i)&gt;=3 else j for i,j in zip(data_choice[\"월 납입액_z\"],data_choice[\"월 납입액\"])] \n\n\n\n총 지불액 이상치 대체\n\nm2 = min([j for i,j in zip(data_choice[\"총지불금액_z\"],data_choice[\"총지불금액\"]) if abs(i)&gt;=3])\n\ndata_choice[\"총지불금액\"] = [m2 if abs(i)&gt;=3 else j for i,j in zip(data_choice[\"총지불금액_z\"],data_choice[\"총지불금액\"])] \n\n\n\n소득변수 이상치 대체\n1 소득 변수는 이상치가 없는 것으로 확인 되었으나, 소득이 아예없는 고객이 많았음\n2 따라서 해당 변수는 이산화 인코딩을 통헤 활용하는게 좋겠당\n\ndata_choice[\"소득\"] = [0 if i == 0 else 1 for i in data_choice[\"소득\"]]\n\ndata_choice[\"소득\"].value_counts()\n\n소득\n1    8972\n0    3028\nName: count, dtype: int64\n\n\n\n\nz-score 컬럼 삭제 & type 변경\n\ndata_choice_n = data_choice.drop(['소득_z','월 납입액_z','총지불금액_z'],axis = 1)\ndata_choice_n.head()\n\n\n\n\n\n\n\n\nAGE\n고용상태\nWillingness to pay/Stay\n상품타입\n교육수준\n소득\n월 납입액\n타 상품 보유 현황\n총지불금액\n거주지사이즈\n자동차\n\n\nCID\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n3\n0\n2.616381\n0\n0\n0\n80\n1.0\n631000\n0\n0\n\n\n2\n1\n1\n6.352530\n0\n0\n1\n80\n4.0\n54000\n0\n0\n\n\n3\n2\n0\n4.974354\n0\n0\n1\n60\n4.0\n362000\n0\n0\n\n\n4\n5\n1\n13.480284\n1\n0\n1\n110\n2.0\n1264000\n1\n0\n\n\n5\n4\n1\n9.776436\n0\n1\n1\n120\n3.0\n947000\n0\n0\n\n\n\n\n\n\n\n\ndata_choice_n.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 12000 entries, 1 to 12000\nData columns (total 11 columns):\n #   Column                   Non-Null Count  Dtype  \n---  ------                   --------------  -----  \n 0   AGE                      12000 non-null  int64  \n 1   고용상태                     12000 non-null  int64  \n 2   Willingness to pay/Stay  12000 non-null  float64\n 3   상품타입                     12000 non-null  int64  \n 4   교육수준                     12000 non-null  int64  \n 5   소득                       12000 non-null  int64  \n 6   월 납입액                    12000 non-null  int64  \n 7   타 상품 보유 현황               12000 non-null  float64\n 8   총지불금액                    12000 non-null  int64  \n 9   거주지사이즈                   12000 non-null  int64  \n 10  자동차                      12000 non-null  int64  \ndtypes: float64(2), int64(9)\nmemory usage: 1.1 MB\n\n\n\ndata_choice_n = data_choice_n.astype(\"float64\")\n\n\ndata_choice_n.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 12000 entries, 1 to 12000\nData columns (total 11 columns):\n #   Column                   Non-Null Count  Dtype  \n---  ------                   --------------  -----  \n 0   AGE                      12000 non-null  float64\n 1   고용상태                     12000 non-null  float64\n 2   Willingness to pay/Stay  12000 non-null  float64\n 3   상품타입                     12000 non-null  float64\n 4   교육수준                     12000 non-null  float64\n 5   소득                       12000 non-null  float64\n 6   월 납입액                    12000 non-null  float64\n 7   타 상품 보유 현황               12000 non-null  float64\n 8   총지불금액                    12000 non-null  float64\n 9   거주지사이즈                   12000 non-null  float64\n 10  자동차                      12000 non-null  float64\ndtypes: float64(11)\nmemory usage: 1.1 MB",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Apple",
      "01. modeling"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Apple/2023-09-26-01. modeling.html#import",
    "href": "posts/mini projects/Fine Apple/2023-09-26-01. modeling.html#import",
    "title": "01. modeling",
    "section": "(1) import",
    "text": "(1) import\n\nfrom yellowbrick.cluster import KElbowVisualizer \nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.cluster import KMeans, DBSCAN",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Apple",
      "01. modeling"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Apple/2023-09-26-01. modeling.html#모델-적합",
    "href": "posts/mini projects/Fine Apple/2023-09-26-01. modeling.html#모델-적합",
    "title": "01. modeling",
    "section": "(2) 모델 적합",
    "text": "(2) 모델 적합\n\nk = list(range(3,10,2))\n\n\n# 모델 만들기 (그룹수 : n_clusters 파라미터 사용)\n# 동일값을 위해 random_state=2023, n_init=10으로 설정값을 같이 해본다.\n# [참고]n_init의 기본 값이 10 이나 warning을 없애기 위해 지정해준다.\nk_model = KMeans(n_init = 10, n_clusters = 3, random_state = 200)\n\nk_model.fit(scaler_data)\n\npred = k_model.predict(scaler_data)\n\n\nk_model.cluster_centers_\n\narray([[ 4.14530612e-01,  8.57142857e-01,  7.62306195e-02,\n         7.83673469e-02,  1.00000000e+00,  1.00000000e+00,\n         1.33455313e-01,  4.25306122e-01,  2.50667950e-01,\n         1.10204082e-01,  8.81632653e-02],\n       [ 4.31137910e-01,  1.00000000e+00,  7.85980651e-02,\n         9.46196660e-02, -4.85722573e-16,  1.00000000e+00,\n         1.37867059e-01,  4.32436611e-01,  2.78258895e-01,\n         9.35374150e-02,  8.99814471e-02],\n       [ 3.93127467e-01, -6.32827124e-15,  7.01693293e-02,\n         8.52101231e-02,  4.48107732e-02,  2.96958440e-01,\n         1.39932588e-01,  4.34796068e-01,  4.25671810e-01,\n         1.17250987e-01,  9.65869515e-02]])",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Apple",
      "01. modeling"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Apple/2023-09-26-01. modeling.html#성능지표-확인-1.-inertia",
    "href": "posts/mini projects/Fine Apple/2023-09-26-01. modeling.html#성능지표-확인-1.-inertia",
    "title": "01. modeling",
    "section": "(3) 성능지표 확인 1. inertia",
    "text": "(3) 성능지표 확인 1. inertia\n\n# 3가지 성능지표를 통해서 확인해보기\n\n# 1. inertia(이너셔) : 각 데이터와 센트로이드(중심) 사이의 평균 제곱거리로 도출한 모델 (model.inertia_로 쓴다)\n# 2. score 매서드: 이너셔의 음수값을 반환( model.score(df))\n# 3. %time : 모델학습에 소요되는 시간 측정\n\nks = list(range(3,11,1))\ninertia_list = []\nfor k in ks: \n    %time\n    exec(f\"k_model_{k} = KMeans(n_init = 10, n_clusters = {k}, random_state = 2023)\")     \n    exec(f\"k_model_{k}.fit(scaler_data)\")\n    exec(f\"inertia_list.append(k_model_{k}.inertia_)\")\n    exec(f\"_iner = k_model_{k}.inertia_\")\n    print(f\"n_cluster : {k}, inertia : {_iner}\") \n    print('---------') # n_cluster, inertia 결과 출력\n\nCPU times: total: 0 ns\nWall time: 0 ns\nn_cluster : 3, inertia : 7630.738131128096\n---------\nCPU times: total: 0 ns\nWall time: 0 ns\nn_cluster : 4, inertia : 6630.463665302053\n---------\nCPU times: total: 0 ns\nWall time: 0 ns\nn_cluster : 5, inertia : 5871.217116262518\n---------\nCPU times: total: 0 ns\nWall time: 0 ns\nn_cluster : 6, inertia : 5275.1942451921\n---------\nCPU times: total: 0 ns\nWall time: 0 ns\nn_cluster : 7, inertia : 4808.309158286751\n---------\nCPU times: total: 0 ns\nWall time: 0 ns\nn_cluster : 8, inertia : 4384.582013588153\n---------\nCPU times: total: 0 ns\nWall time: 0 ns\nn_cluster : 9, inertia : 3987.128229343856\n---------\nCPU times: total: 0 ns\nWall time: 0 ns\nn_cluster : 10, inertia : 3693.3064711892653\n---------\n\n\n\n#plt로 결과출력\n\nplt.plot(ks, inertia_list,\"-ob\")\nplt.show()",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Apple",
      "01. modeling"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Apple/2023-09-26-01. modeling.html#성능지표-확인-2.-elbow-method",
    "href": "posts/mini projects/Fine Apple/2023-09-26-01. modeling.html#성능지표-확인-2.-elbow-method",
    "title": "01. modeling",
    "section": "(4) 성능지표 확인 2. Elbow Method",
    "text": "(4) 성능지표 확인 2. Elbow Method\n\nyellowbrick의 k-Elbow Mehod를 활용해서 최적의 k 값을 구하기(k값 결정하기 쉽게 도와주는 함수)\n\n\n# 1. 모델 선언하기(random_state=2023, n_init = 10 으로 설정)(model_E로 할당)\nmodel = KMeans( n_init=10, random_state = 200)\n\n# 2. KElbowVisualizer 에 k-means 모델과 k값 넣어서 만들기(Elbow_M 에 할당)\n# k값은 k=(3,11)사이의 값중에서 찾는 것으로 넣으면 된다.\nmodel_E = KElbowVisualizer(model, k=(3,11))\n\n\n# 3. Elbow 모델 학습하기(fit)\nmodel_E.fit(scaler_data)\n\n\n# 4. Elbow 모델 확인하기(show()활용)\nmodel_E.show()\n\n\n\n\n\n\n\n\n- 최적의 k값은 5로 선정\n\ndistortion score : 각 데이터들의 군집 중심과의 평균 거리",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Apple",
      "01. modeling"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Apple/2023-09-26-01. modeling.html#최적의-k-값으로-모델링",
    "href": "posts/mini projects/Fine Apple/2023-09-26-01. modeling.html#최적의-k-값으로-모델링",
    "title": "01. modeling",
    "section": "(5) 최적의 k 값으로 모델링",
    "text": "(5) 최적의 k 값으로 모델링\n\n# 1. scale이 안된 원본 data 로드\n\ndata_o = pd.read_csv(\"customers_seg.csv\", encoding = \"CP949\")\n\n# 2. 'CID'는 활용하지 않을 예정으로 index\ndata_o.set_index(\"CID\",inplace=True)\n\n# 3. 데이터 상위 5개 확인하기\ndata_o.head()\n\n\n\n\n\n\n\n\nAGE\n등록(계/피)\n고용상태\n성별\nWillingness to pay/Stay\n갱신\n상품타입\n교육수준\n소득\n지역\n결혼여부\n월 납입액\nVOC\n타 상품 보유 현황\n온라인방문빈도\n갱신인센티브\n판매채널\n총지불금액\n자동차\n거주지사이즈\n\n\nCID\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n3\n피보험자\n무직\n1\n2.616381\n0\n기본\n대학졸업\n0\n도시근교\n미혼\n80\n0\n1\n자주방문\n없음\n자사영업\n631000\n일반세단\n소\n\n\n2\n1\n계약자\n고용\n0\n6.352530\n0\n기본\n고졸이하\n102887400\n시골\n미혼\n80\n1\n4이상\n비방문\n포인트\n인터넷\n54000\n일반세단\n중\n\n\n3\n2\n계약자\n휴직\n0\n4.974354\n0\n기본\n대학졸업\n22159500\n도시근교\n기혼\n60\n0\n4이상\n비방문\n할인\n자사영업\n362000\n일반세단\n중\n\n\n4\n5\n계약자\n고용\n1\n13.480284\n0\n고급\n고졸이하\n51562500\n도시근교\n기혼\n110\n0\n2\n비방문\n할인\n자사영업\n1264000\n컴팩트카\n대\n\n\n5\n4\n계약자\n고용\n0\n9.776436\n0\n기본\n석사\n26820200\n도시근교\n기혼\n120\n0\n3\n비방문\n없음\n대리점\n947000\nSUV\n중\n\n\n\n\n\n\n\n\nk4 = 5\n\nk_model = KMeans(random_state = 200, n_init=10, n_clusters = k4 )\n\nk_model.fit(scaler_data)\n\nkmeans_p = k_model.predict(scaler_data)\n\nscaler_data[\"clust\"] = kmeans_p\ndata_d1 = pd.concat([data_o.reset_index(drop = True), scaler_data[[\"clust\"]]], axis = 1)\n\n- 원본 데이터와 합치기\n\nindex_label = list(range(1,data_d1.shape[0]+1))\nindex_label[-1]\ndata_d1.index = index_label\ndata_d1 = data_d1.rename_axis(index = \"CID\")\noutput = data_d1.copy()\noutput.head()\n\n\n\n\n\n\n\n\nAGE\n등록(계/피)\n고용상태\n성별\nWillingness to pay/Stay\n갱신\n상품타입\n교육수준\n소득\n지역\n...\n월 납입액\nVOC\n타 상품 보유 현황\n온라인방문빈도\n갱신인센티브\n판매채널\n총지불금액\n자동차\n거주지사이즈\nclust\n\n\nCID\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n3\n피보험자\n무직\n1\n2.616381\n0\n기본\n대학졸업\n0\n도시근교\n...\n80\n0\n1\n자주방문\n없음\n자사영업\n631000\n일반세단\n소\n2\n\n\n2\n1\n계약자\n고용\n0\n6.352530\n0\n기본\n고졸이하\n102887400\n시골\n...\n80\n1\n4이상\n비방문\n포인트\n인터넷\n54000\n일반세단\n중\n1\n\n\n3\n2\n계약자\n휴직\n0\n4.974354\n0\n기본\n대학졸업\n22159500\n도시근교\n...\n60\n0\n4이상\n비방문\n할인\n자사영업\n362000\n일반세단\n중\n4\n\n\n4\n5\n계약자\n고용\n1\n13.480284\n0\n고급\n고졸이하\n51562500\n도시근교\n...\n110\n0\n2\n비방문\n할인\n자사영업\n1264000\n컴팩트카\n대\n0\n\n\n5\n4\n계약자\n고용\n0\n9.776436\n0\n기본\n석사\n26820200\n도시근교\n...\n120\n0\n3\n비방문\n없음\n대리점\n947000\nSUV\n중\n3\n\n\n\n\n5 rows × 21 columns",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Apple",
      "01. modeling"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Apple/2023-09-26-01. modeling.html#프로파일링",
    "href": "posts/mini projects/Fine Apple/2023-09-26-01. modeling.html#프로파일링",
    "title": "01. modeling",
    "section": "(6) 프로파일링",
    "text": "(6) 프로파일링\n- 군집의 구조와 내용을 분석하고 도메인 및 현업업무의 ’추론’을 바탕으로 분석의 결과를 적용 가능하도록 하는 과정. 데이터를 통해서 군집별 특성을 파악하는 것에 목적은 두는 기법\n\na. 군집별 수치형 변수 분포 확인\n\nplt.rc(\"font\", family = \"Malgun Gothic\")\nsns.set(font=\"Malgun Gothic\", \nrc={\"axes.unicode_minus\":False}, style='white')\n\n\nfig, axes = plt.subplots(2,2, figsize = (12,8))\n\n\nf_lst = [[\"Willingness to pay/Stay\", \"소득\"],[\"월 납입액\",\"총지불금액\",\"clust\"]]\n\nfor i in range(2) : \n    for j in range(2) : \n        sns.histplot(x = f_lst[i][j], data = output, hue=\"clust\", ax = axes[i][j], palette='cool') \n        \nfig.tight_layout()\nfig.show()\n\nC:\\Users\\rkdcj\\AppData\\Local\\Temp\\ipykernel_4972\\3364328251.py:11: UserWarning:\n\nMatplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n\n\n\n\n\n\n\n\n\n\n\nf_lst = [\"Willingness to pay/Stay\", \"소득\",\"월 납입액\",\"총지불금액\",\"clust\"]\n\n\nagg1 = output[f_lst].groupby(\"clust\").\\\n    agg({\"Willingness to pay/Stay\": np.mean,\n          \"소득\": np.mean,\n          \"월 납입액\": np.mean,\n          \"총지불금액\": np.mean,\n          })\n\n\n\nb. 군집간 수치형 변수들의 차이 검정\n\nfor i in range(5) : \n    exec(f\"w_{i} = output[f_lst].loc[map(lambda x : x == i,output.clust), 'Willingness to pay/Stay']\")\nstat = spst.f_oneway(w_0,w_1,w_2,w_3,w_4)[0]\npvalue = spst.f_oneway(w_0,w_1,w_2,w_3,w_4)[1]\nresult = pd.DataFrame(columns = [\"stat\",\"pvalue\",\"var\"])\nresult.loc[0] = [stat, pvalue,\"Willingness to pay/Stay\"] \n\n\nresult\n\n\n\n\n\n\n\n\nstat\npvalue\nvar\n\n\n\n\n0\n31.37888\n4.856769e-26\nWillingness to pay/Stay\n\n\n\n\n\n\n\n\nfor i in range(5) : \n    exec(f\"w_{i} = output[f_lst].loc[map(lambda x : x == i,output.clust), '소득']\")\n\n    stat = spst.f_oneway(w_0,w_1,w_2,w_3,w_4)[0]\npvalue = spst.f_oneway(w_0,w_1,w_2,w_3,w_4)[1]\nresult.loc[1] = [stat, pvalue,\"소득\"] \n\n\nfor i in range(5) : \n    exec(f\"w_{i} = output[f_lst].loc[map(lambda x : x == i,output.clust), '월 납입액']\")\n\nstat = spst.f_oneway(w_0,w_1,w_2,w_3,w_4)[0]\npvalue = spst.f_oneway(w_0,w_1,w_2,w_3,w_4)[1]\nresult.loc[2] = [stat, pvalue,\"월 납입액\"] \n\n\nfor i in range(5) : \n    exec(f\"w_{i} = output[f_lst].loc[map(lambda x : x == i,output.clust), '총지불금액']\")\n\nstat = spst.f_oneway(w_0,w_1,w_2,w_3,w_4)[0]\npvalue = spst.f_oneway(w_0,w_1,w_2,w_3,w_4)[1]\nresult.loc[3] = [stat, pvalue,\"총지불금액\"] \n\n\nresult\n\n\n\n\n\n\n\n\nstat\npvalue\nvar\n\n\n\n\n0\n31.378880\n4.856769e-26\nWillingness to pay/Stay\n\n\n1\n5476.648834\n0.000000e+00\n소득\n\n\n2\n3.560818\n6.578685e-03\n월 납입액\n\n\n3\n444.750442\n0.000000e+00\n총지불금액\n\n\n\n\n\n\n\n\nagg1\n\n\n\n\n\n\n\n\nWillingness to pay/Stay\n소득\n월 납입액\n총지불금액\n\n\nclust\n\n\n\n\n\n\n\n\n0\n9.916307\n6.917161e+07\n101.339761\n457605.683837\n\n\n1\n7.967621\n6.964916e+07\n97.863079\n441794.618124\n\n\n2\n8.367462\n0.000000e+00\n101.172391\n739828.599736\n\n\n3\n8.940833\n6.234310e+07\n98.702041\n404278.367347\n\n\n4\n8.452066\n2.504257e+07\n99.179046\n603396.403440\n\n\n\n\n\n\n\n\n\nc. 타겟 군집 선정\n- 0번 군집 : 기대확률이 상위, 소득이 높고, 월 납입액 중간, 총 지불금액이 하위권인 그룹\n- 1번 군집 : 기대확률 상위권, 소득이 중간, 월납입액 상위, 총 지불금액이 상위권인 그룹 (가장 마케팅 전략을 세우기 좋은 그룹)\n- 2번 군집 : 기대확률 중간, 소득이 없음, 월납입액 상위, 총 지불금액이 상위권인 그룹\n- 3번 군집 : 기대확률 중간, 소득이 중간, 월납입액 적음, 총 지불금액이 하위권인 그룹\n- 4번 군집 : 기대확률 중간, 소득과 월납입액이 높고, 총 지불금액이 하위권인 그룹\n- 5번 군집 : 기대확률, 월 납입액이 적고, 총 지불금액이 중간 정도 되는 그룹",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Apple",
      "01. modeling"
    ]
  },
  {
    "objectID": "posts/mini projects/AIVLE/2023-10-17-01. 키워드 시각화 및 교육 인사이트 도출.html",
    "href": "posts/mini projects/AIVLE/2023-10-17-01. 키워드 시각화 및 교육 인사이트 도출.html",
    "title": "01. 키워드 시각화 및 교육 인사이트 도출",
    "section": "",
    "text": "Intro\n- 자연어 데이터를 시각화하여 중요한 키워드를 도출하고 어느 부분에서 개선이 필요한지 인사이트를 도출\n- 이를 통해, 후기 교육생들을 위한 코칭 프로세스 개선 방안 마련\n\n\n0. import\n\n\nCode\nimport pandas as pd    # pandas 데이터프레임을 생성/편집하기 위해 사용 합니다.\nimport matplotlib.pyplot as plt   \nfrom wordcloud import WordCloud    \nfrom collections import Counter   \nimport re    \nfrom PIL import Image \nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\nplt.rcParams['font.family'] = 'Malgun Gothic'\nplt.rcParams['axes.unicode_minus'] = False\n\nfrom mecab import MeCab\nmecab = MeCab()\n\n\n\n\n\n1. 데이터 로드\n- 사전에 전처리를 마친 데이터를 불러옴\n\ndata = pd.read_csv(\"전처리data.csv\").loc[:,[\"문의유형\",\"한글자제거\"]] ## 전처리 data\nresult = pd.read_csv(\"전처리tidydata.csv\")\n\n\n\n2. 명사 추출\n- 필터품사\n- 코드와 웹에선 영어 단어가 많으므로 외국어(SL)도 보존\n- 명사는 일반 명사(NNG)와 고유명사(NNP)만 사용\n\nf_col =[\"NNG\",\"SL\",\"NNP\"]\ntitle = result[\"문의유형\"].unique().tolist()\n\n\nresult2 = pd.DataFrame()\n\nfor i in range(len(title)) :\n    temp = result.loc[result.문의유형 == title[i], \"word\"]\n    temp = \" \".join([str(i) for i in temp])\n    temp = [i[0] for i in mecab.pos(temp) if i[1] in f_col]\n    temp = pd.DataFrame({\"word\": temp})\n    temp[\"문의유형\"] = title[i]\n    result2 = pd.concat([result2,temp], axis = 0)\n\n\n\n3. 한글자 단어 제거\n\nresult2 = result2.loc[map(lambda x : len(x) &gt;=2, result2.word), :]\n\n\n\n4. 전체 단어에서 불용어 판단\n- 의외로 출현 빈도수가 1회인 단어들은 mnist와 같은 중요한 데이터셋의 정보를 담고 있음\n- 그에 반해 빈도수가 많은 단어들은 문서를 자동 분류하기에 적합한 단어라고 보기 어렵다(딱히 차별성이 없어보임..)\n- 따라서 전체 단어에서 50회 이상 출현한 단어를 불용어로 판단\n\nresult2.groupby(\"word\",as_index = False)[[\"word\"]].\\\n                    value_counts().sort_values(\"count\",ascending=False).head(10)\n\n\n\n\n\n\n\n\nword\ncount\n\n\n\n\n6198\n사용\n237\n\n\n7490\n진행\n217\n\n\n7840\n파일\n212\n\n\n5889\n문제\n197\n\n\n5565\n데이터\n192\n\n\n6574\n실행\n186\n\n\n8104\n확인\n180\n\n\n7134\n입력\n164\n\n\n6567\n실습\n146\n\n\n6087\n부분\n143\n\n\n\n\n\n\n\n\nresult2.groupby(\"word\",as_index = False)[[\"word\"]].\\\n                                value_counts().plot(kind = \"hist\", backend = \"plotly\",\n                                                    x= \"count\", height = 400)\n\n                                                \n\n\n\ntemp = result2.groupby(\"word\",as_index = False)[[\"word\"]].value_counts()\ntemp = temp.loc[[i &gt; 50 for i in temp[\"count\"]],:]\nstop_word = temp[\"word\"].tolist()\n\n\n\n5. 문의 유형별 단어 카운트\n\nc_table = result2.groupby([\"문의유형\"], as_index = False)[[\"word\"]].value_counts()\nc_table = c_table.loc[[i not in stop_word for i in c_table[\"word\"]], :]\n\n\n\n6. 문의 유형별 단어 분포 확인\n\nc_table.plot(x = \"count\", kind = \"hist\",\n              backend = \"plotly\", color = \"문의유형\",\n              facet_col = \"문의유형\", facet_col_wrap = 3,width = 800, height = 600)\n\n                                                \n\n\n\n\n7. 문의 유형별 워드클라우드 시각화\n\nfor i in range(len(title)) : \n    temp_word_count = c_table.loc[c_table.문의유형 == title[i], [\"word\",\"count\"]].\\\n                            set_index(\"word\").to_dict()[\"count\"]\n    exec(f'''temp_cloud{i} = WordCloud(\n                                background_color  = \"white\",\n                                font_path = \"projects/posts/mini projects/AIVLE/malgun.ttf\",\n                                ).generate_from_frequencies(temp_word_count)''')\n\n\nfig, axes = plt.subplots(2,3, figsize = (12, 8))\n\ntemp_cloud = [[temp_cloud0,temp_cloud1, temp_cloud2],\n              [temp_cloud3,temp_cloud4, temp_cloud5]]\n\ntitle2 = [['코드1', '코드2', '웹'],\n           ['이론', '시스템 운영', '원격']]\n\nfor i in range(2) :\n    for j in range(3) : \n        axes[i][j].imshow(temp_cloud[i][j])\n        axes[i][j].axis(\"off\")\n        axes[i][j].set_title(title2[i][j])\n\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n\n8. insight\n1 코드 1에서는 리스트, 케이스, 검색, 실패 등 초반부에 파이썬에 대한 개념이 잘 잡히지 않았고 코딩 마스터즈 관련 질문도 많이 보인다.\n\n초반부에 파이선에 대한 개념 위주의 실습을 더욱 구체화한다면, 후기 에이블러들이 학습하는데 도움이 될 것 같다.\n\n2 코드 2에서는 모델링 관련 문의가 많다.\n\n수업 중 느꼈지만, 먼가 머신러닝, 딥러닝 모델 학습 기간이 너무 짧은 것 같다. 시간적인 부분에 대한 개선이 필요하다.\n\n3 웹에서는 페이지 작동과 환경 구성, 서버 관련 문의가 많다.\n\n특히 스턴, 종료라는 단어가 눈에 띄는데 어감상 불편한걸 보니 전 기수에서 서버관련 이슈가 많았나보다.\n\n4 이론에서는 검정 정의, 분포, 계수 등에 질문이 많아 보인다.\n\n이론이 안잡히면 코딩하기가 어렵다. 뭔가 이론을 한방에 요약해주는 한방 pdf 자료를 제공해주면 에이블러들이 학습하는데 도움이 될 것 같다.\n\n5 시스템 운영, 원격\n\n시스템 운영에서는 과제, 발표, 프로젝트, 시험 등 학습 외적인 질문이 많다.\n이 부분은 KT 관계자들과 이야기할 필요가 있어보인다.\n\n6 원격에서는 에이블러분들의 요청들을 볼 수 있었다.\n\n그리고 감사라는 단어가 상위 빈도로 보이는데, 튜터님들과 에이블러들 사이에 어떤 돈독함을 잘 보여주는 것 같다.",
    "crumbs": [
      "Posts",
      "mini projects",
      "AIVLE",
      "01. 키워드 시각화 및 교육 인사이트 도출"
    ]
  },
  {
    "objectID": "posts/2023-07-31-00.intro.html",
    "href": "posts/2023-07-31-00.intro.html",
    "title": "00. quarto blog",
    "section": "",
    "text": "- 어… 일단 평소에도 quarto를 이용해서 웹사이트를 관리했지만… 뭔가 처음 깃허브를 접하구 하시는 분들은 이 플랫폼을 사용할 때 되게 난항이 있을것 같다… (내가 그랬다…)\n- 그리고 원래 만들어 놓았던 사이트는 뭔가 좀 지저분한 느낌이 들어서….\n- 에이블스쿨 하면서 배운것들 기록할 때는 뭔가 깔끔한 공간에 하고 싶기도 하다.\n- 이참에 절차를 확실히 내가 적어두자!\n\n\n- quarto download link : 여기서 quarto를 다운받자!\n\n\n\n- Terminal을 켠다음에 아래와 같은 명령어를 입력한다!\n(그.. 명령어 입력할 때 현재 자기 주피터 킬때 켜지는 폴더로 옮긴 다음에 수행하자… 골치 아프다ㅜㅜ)\nquarto create project website gcsite\n- 그러면 다음과 같은 이미지가 보인다\n\n- 저기 open with 어찌고 보이는데 d버튼 누르면 (don’t open)으로 넘어가니 그걸 선택한 후 엔터를 눌러준다!\n- 그러면 아래 이미지처럼 맨 밑에 gcsite라는 폴더가 생긴 것을 볼 수 있다.\n\n\n\n\n- git bash 쓰는 사람들 많던데 난 github desktop이 훨씬 편하다.\n- git 알못이기 때문에 많은 것을 알기 위해 괴롭고 싶지 않다.\n- 뭐 여튼 깃허브 데스크탑을 킨다.\n- 상단 메뉴바 \\(\\to\\) File \\(\\to\\) Add local repository\n- 그러면 아래와 같은 경고문이 뜬다.\n\n- local하고 연결하고 싶은데 깃허브에는 gcsite가 없으니 대충 만들어 달라는 것임 “create a repository” 를 눌러주자.\n\n- 무시, 걍 create repository ㄱㄱ\n- 그러면 깃허브 데스크탑에서 너 방금 만든거 너꺼 깃허브에 Publish 할거냐고 물어봄\n\n- Publish repository 눌러주면 끝~~ (단, publish할 때 private 체크박스는 해제하구 하자!)\n- 그 다음 내가 생성산 gcsite 저장소 setting으로 넘어가서 pages를 클릭!\n- 아래와 같이 branch를 수정 후 save 버튼 눌러주자\n\n\n\n\n- quarto 원리 : 작성한 ipynb파일 html파일로 출력해서 그 html파일들로 웹사이트를 구성하는 것1\n- step1. posts와 docs라는 폴더를 만들자\n\nposts는 내가 작성하는 ipynb파일들이 들어갈거고, docs에는 html파일이 들어갈 것이다.\n\n- step2. index 파일 수정\n\nindex파일은 뭐랄까 네비게이터 역할이랄까 아래와 같이 바꿔주자\n\n---\ntitle: \"GC site\"\nlisting:\n  contents: posts\n  sort: [date desc, title]\n  type: table\n  categories: true\n  sort-ui: true\n  filter-ui: true\npage-layout: full\ntitle-block-banner: true\n---\n- step3. _quarto.uml 파일 수정 \\(\\to\\) 템플릿이랑 디자인 이쁜거 많으니 본인 입맛에 맞게 수정하면 됩니당\nproject:\n  type: website\n  output-dir : docs  \nwebsite:\n  title: \"GC site\"\n  page-navigation: true\n  navbar:\n    right:\n      - icon : github\n        href : https://github.com/gangcheol/\n  sidebar:\n    style: \"docked\"\n    search: True\n    contents: auto\n    \nformat:\n  html:\n    css: styles.css\n    toc: true\n    code-fold : False\n    code-line-numbers : True\n    code-copy : True\n\ntheme :\n  light : flatly\n  \neditor : visual\n- step4. 앞서 만든 posts폴더에 아무 파일이나 만들어보자\n\n- step5. 그 후 다시 터미널에서 내가 생성한 폴더로 이동\n필자의 경우는 cd gcsite\n- step6. quarto render 입력\n- step7. github desktop보면 난리가 났을 것이다. 막 일을 좀 많이 했음.\n\n로컬하고 연결되어 있으니 로컬이 하고 있는 걸 다적어서 그럼\n\n\n\n저기 내가 밑에 이러한 기록을 init이라고 써놨다. 저건 내가 로컬에서 한 행동을 내 깃허브 로컬에 저장할 건데, 그 행동을 init이라고 쓴거\n이제 저 Commit to main 버튼을 눌러주고 가운데 화면에 뜨는 push origin을 눌러주자!\n\n- 마지막!! 아까 깃허브 로컬 셋팅에서 pases란에 잠시 후에 들어가보면 다음과 같은 것을 볼 수 있다.\n\n- 저 링크로 들어가면 내가 만든 웹사이트 초안을 볼 수 있다.\n- 링크",
    "crumbs": [
      "Posts",
      "00. quarto blog"
    ]
  },
  {
    "objectID": "posts/2023-07-31-00.intro.html#install",
    "href": "posts/2023-07-31-00.intro.html#install",
    "title": "00. quarto blog",
    "section": "",
    "text": "- quarto download link : 여기서 quarto를 다운받자!",
    "crumbs": [
      "Posts",
      "00. quarto blog"
    ]
  },
  {
    "objectID": "posts/2023-07-31-00.intro.html#website-생성",
    "href": "posts/2023-07-31-00.intro.html#website-생성",
    "title": "00. quarto blog",
    "section": "",
    "text": "- Terminal을 켠다음에 아래와 같은 명령어를 입력한다!\n(그.. 명령어 입력할 때 현재 자기 주피터 킬때 켜지는 폴더로 옮긴 다음에 수행하자… 골치 아프다ㅜㅜ)\nquarto create project website gcsite\n- 그러면 다음과 같은 이미지가 보인다\n\n- 저기 open with 어찌고 보이는데 d버튼 누르면 (don’t open)으로 넘어가니 그걸 선택한 후 엔터를 눌러준다!\n- 그러면 아래 이미지처럼 맨 밑에 gcsite라는 폴더가 생긴 것을 볼 수 있다.",
    "crumbs": [
      "Posts",
      "00. quarto blog"
    ]
  },
  {
    "objectID": "posts/2023-07-31-00.intro.html#깃허브-로컬-연결",
    "href": "posts/2023-07-31-00.intro.html#깃허브-로컬-연결",
    "title": "00. quarto blog",
    "section": "",
    "text": "- git bash 쓰는 사람들 많던데 난 github desktop이 훨씬 편하다.\n- git 알못이기 때문에 많은 것을 알기 위해 괴롭고 싶지 않다.\n- 뭐 여튼 깃허브 데스크탑을 킨다.\n- 상단 메뉴바 \\(\\to\\) File \\(\\to\\) Add local repository\n- 그러면 아래와 같은 경고문이 뜬다.\n\n- local하고 연결하고 싶은데 깃허브에는 gcsite가 없으니 대충 만들어 달라는 것임 “create a repository” 를 눌러주자.\n\n- 무시, 걍 create repository ㄱㄱ\n- 그러면 깃허브 데스크탑에서 너 방금 만든거 너꺼 깃허브에 Publish 할거냐고 물어봄\n\n- Publish repository 눌러주면 끝~~ (단, publish할 때 private 체크박스는 해제하구 하자!)\n- 그 다음 내가 생성산 gcsite 저장소 setting으로 넘어가서 pages를 클릭!\n- 아래와 같이 branch를 수정 후 save 버튼 눌러주자",
    "crumbs": [
      "Posts",
      "00. quarto blog"
    ]
  },
  {
    "objectID": "posts/2023-07-31-00.intro.html#문서-생성",
    "href": "posts/2023-07-31-00.intro.html#문서-생성",
    "title": "00. quarto blog",
    "section": "",
    "text": "- quarto 원리 : 작성한 ipynb파일 html파일로 출력해서 그 html파일들로 웹사이트를 구성하는 것1\n- step1. posts와 docs라는 폴더를 만들자\n\nposts는 내가 작성하는 ipynb파일들이 들어갈거고, docs에는 html파일이 들어갈 것이다.\n\n- step2. index 파일 수정\n\nindex파일은 뭐랄까 네비게이터 역할이랄까 아래와 같이 바꿔주자\n\n---\ntitle: \"GC site\"\nlisting:\n  contents: posts\n  sort: [date desc, title]\n  type: table\n  categories: true\n  sort-ui: true\n  filter-ui: true\npage-layout: full\ntitle-block-banner: true\n---\n- step3. _quarto.uml 파일 수정 \\(\\to\\) 템플릿이랑 디자인 이쁜거 많으니 본인 입맛에 맞게 수정하면 됩니당\nproject:\n  type: website\n  output-dir : docs  \nwebsite:\n  title: \"GC site\"\n  page-navigation: true\n  navbar:\n    right:\n      - icon : github\n        href : https://github.com/gangcheol/\n  sidebar:\n    style: \"docked\"\n    search: True\n    contents: auto\n    \nformat:\n  html:\n    css: styles.css\n    toc: true\n    code-fold : False\n    code-line-numbers : True\n    code-copy : True\n\ntheme :\n  light : flatly\n  \neditor : visual\n- step4. 앞서 만든 posts폴더에 아무 파일이나 만들어보자\n\n- step5. 그 후 다시 터미널에서 내가 생성한 폴더로 이동\n필자의 경우는 cd gcsite\n- step6. quarto render 입력\n- step7. github desktop보면 난리가 났을 것이다. 막 일을 좀 많이 했음.\n\n로컬하고 연결되어 있으니 로컬이 하고 있는 걸 다적어서 그럼\n\n\n\n저기 내가 밑에 이러한 기록을 init이라고 써놨다. 저건 내가 로컬에서 한 행동을 내 깃허브 로컬에 저장할 건데, 그 행동을 init이라고 쓴거\n이제 저 Commit to main 버튼을 눌러주고 가운데 화면에 뜨는 push origin을 눌러주자!\n\n- 마지막!! 아까 깃허브 로컬 셋팅에서 pases란에 잠시 후에 들어가보면 다음과 같은 것을 볼 수 있다.\n\n- 저 링크로 들어가면 내가 만든 웹사이트 초안을 볼 수 있다.\n- 링크",
    "crumbs": [
      "Posts",
      "00. quarto blog"
    ]
  },
  {
    "objectID": "about.html#contact",
    "href": "about.html#contact",
    "title": "About me",
    "section": "contact",
    "text": "contact\n\nE-mail : rkdcjf8232@gmail.com",
    "crumbs": [
      "**About me**"
    ]
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About me",
    "section": "Education",
    "text": "Education\n\n전북대학교 통계학 학사(부전공 : 컴퓨터공학) | 2015.03 ~ 2021.02\n전북대학교 통계학 석사 | 2021.03 ~ 2023.02",
    "crumbs": [
      "**About me**"
    ]
  },
  {
    "objectID": "about.html#certificate",
    "href": "about.html#certificate",
    "title": "About me",
    "section": "Certificate",
    "text": "Certificate\n\n사회조사분석사 2급\n데이터분석준전문가(ADsP)\nAICE Associate",
    "crumbs": [
      "**About me**"
    ]
  },
  {
    "objectID": "about.html#skill",
    "href": "about.html#skill",
    "title": "About me",
    "section": "Skill",
    "text": "Skill\n\nR ⭐⭐⭐⭐\nPython ⭐⭐⭐⭐\nEXCEL ⭐⭐⭐⭐\nSPSS ⭐⭐⭐⭐\nSQL ⭐⭐⭐\nJAVA, C ⭐⭐",
    "crumbs": [
      "**About me**"
    ]
  },
  {
    "objectID": "about.html#extracurricular-activities",
    "href": "about.html#extracurricular-activities",
    "title": "About me",
    "section": "Extracurricular Activities",
    "text": "Extracurricular Activities\n\n국민연금공단 빅데이터부 현장실습 | 2020. 03 ~ 2020. 06\n지역 문화산업 융복합 데이터 전문가 과정 | 과학기술정보통신부, 한국데이터산업진흥원 | 2021. 06 ~ 2021. 08\n빅데이터 혁신공유대학사업 서포터즈 |전북대학교 빅데이터 현신공유대학사업| 2021. 07. 01 ~ 2021. 10. 31\nKT AIVLE School DX Consultant Track | KT | 2023. 08. 08 ~ 2024. 01. 25",
    "crumbs": [
      "**About me**"
    ]
  },
  {
    "objectID": "about.html#publication",
    "href": "about.html#publication",
    "title": "About me",
    "section": "Publication",
    "text": "Publication\n\n데이터 분석을 통한 지역별 고령친화도 시각화\n\n김영선, 강민구, 이강철 등 | 문화융복합아카이빙연구소 | 2021. 10 | 기록관리/보존\n\n핵심어 추출 및 데이터 증강기법을 이용한 텍스트 분류 모델 성능 개선\n\n이강철, 안정용 | 한국자료분석학회 | 한국자료분석학회 | 2022. 10 | 통계학",
    "crumbs": [
      "**About me**"
    ]
  },
  {
    "objectID": "about.html#awards",
    "href": "about.html#awards",
    "title": "About me",
    "section": "Awards",
    "text": "Awards\n\n학회장상 | 한국통계학회 | 2023. 02. 22\nAIVLE Big Project Practical | KT | 2024. 01. 25",
    "crumbs": [
      "**About me**"
    ]
  },
  {
    "objectID": "about.html#interest",
    "href": "about.html#interest",
    "title": "About me",
    "section": "Interest",
    "text": "Interest\n\nNLP\nAction Recognition, Object Detection\nData Science\nGrowth Hacking",
    "crumbs": [
      "**About me**"
    ]
  },
  {
    "objectID": "about.html#my-blog",
    "href": "about.html#my-blog",
    "title": "About me",
    "section": "My blog",
    "text": "My blog\n 1. Lecture\n\nR for Data Science\nSpecial Topics in Data Visualization\nIntroduction to Python\nSpecial Topics in Big Data Analysis\nSpecial Topics in Machine Learning\n\n 2. Tableau\n\nTableau Practice\n\n 3. DX\n\nDX Consultant Education\n\n 4. Study\n\nISLP Study\nAlgorithm Study\n\n 5. Projects\n\nMini Project 1 : 행동 데이터 분류 AI 모델링",
    "crumbs": [
      "**About me**"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Projects",
    "section": "",
    "text": "links\n\nlectureStudymini projectsbig projectspublications\n\n\n1 R for Data Science\n2 Special Topics in Data Visualization\n3 Introduction to Python\n4 Special Topics in Big Data Analysis\n5 Special Topics in Machine Learning\n6 Tableau Practice\n7 DX Consultant Education\n\n\n1 ISLP Study\n2 Algorithm Study\n\n\n1 mini project1 : Fine Watch, 계단오르기 행동감지 모델링\n2 mini project2 : Fine Apple, 군집분석을 통한 고객 segment 개발\n3 mini project3 : AIVLE, 1:1 문의유형 자동분류 모델링 및 교육 인사이트 도출\n\n\n\nISLP Study\nAlgorithm Study\n\n\n\n1 데이터 분석을 통한 지역별 고령친화도 시각화\n\n김영선, 강민구, 이강철 등 | 문화융복합아카이빙연구소 | 2021. 10 | 기록관리/보존\n\n2 핵심어 추출 및 데이터 증강기법을 이용한 텍스트 분류 모델 성능 개선\n\n이강철, 안정용 | 한국자료분석학회 | 한국자료분석학회 | 2022. 10 | 통계학\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nOct 17, 2023\n\n\n01. 키워드 시각화 및 교육 인사이트 도출\n\n\nGC \n\n\n\n\nOct 16, 2023\n\n\n00. 문의 유형 자동분류 모델링 생성\n\n\nGC \n\n\n\n\nSep 26, 2023\n\n\n00. EDA\n\n\nGC \n\n\n\n\nSep 26, 2023\n\n\n01. modeling\n\n\nGC \n\n\n\n\nSep 20, 2023\n\n\n00. EDA & Modeling\n\n\nGC \n\n\n\n\nSep 20, 2023\n\n\n01. model tuning & save\n\n\nGC \n\n\n\n\nJul 31, 2023\n\n\n00. quarto blog\n\n\nGC \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html",
    "href": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html",
    "title": "00. 문의 유형 자동분류 모델링 생성",
    "section": "",
    "text": "- AIVLE SCHOOL 1:1 문의 분석팀에는 문의에 대한 답변을 위해 문의 내용을 일일이 확인하여 분야별 담당 전문 튜터에게 전달해야 한다.\n- 그러나 수많은 1:1 문의를 읽고 분양를 나누는 일은 많은 리소스와 시간이 필요\n- 특히, 최근 일반 문의가 코드 문의에 섞여 들어오는 일이 점점 증가하고 있음\n- 목표 1 : 코드문의와 일반 문의를 자동으로 구별할 수 있는 자연어 딥러닝 모델을 생성\n- 목표 2 : 테스트 데이터를 통해 모델을 고도화",
    "crumbs": [
      "Posts",
      "mini projects",
      "AIVLE",
      "00. 문의 유형 자동분류 모델링 생성"
    ]
  },
  {
    "objectID": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#데이터-로드",
    "href": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#데이터-로드",
    "title": "00. 문의 유형 자동분류 모델링 생성",
    "section": "(1) 데이터 로드",
    "text": "(1) 데이터 로드\n\ntrain_df = pd.read_csv('QnA_train_data.csv')\ntrain_df.head()\n\n\n\n\n\n\n\n\n트랙\n지역\n문의내용\n문의유형\n\n\n\n\n0\nDX컨설턴트\n수도권\ninplace= True 를 사용하는 기준이 존재하는 것인지, 아니면 함수나 메소드...\n코드2\n\n\n1\nAI개발자\n수도권\n참조파일2에 대한 (yolo부분) 답안 파일이 올라오지 않은 것 같습니다!\n시스템 운영\n\n\n2\nAI개발자\n전남/전북\nAICE 시험 관련하여 이렇게 1대1로 질문하는게 맞나요..?\\n맞다면, 질문드립니...\n시스템 운영\n\n\n3\nDX컨설턴트\n충남/충북\n예제는 잘 작동한 것 같은데 채점하니 케이스 1만 성공하고 나머지가 fail이 떠 ...\n코드1\n\n\n4\nDX컨설턴트\n대구/경북\n제주관광공사를 대상으로 관광지 순환 버스 솔루션을 도입하여\\n운전을 못하는 관광객 ...\n이론\n\n\n\n\n\n\n\n- 불필요한 열 삭제\n\ntrain_df.drop([\"트랙\", \"지역\"], axis = 1, inplace = True)\ntrain_df.head()\n\n\n\n\n\n\n\n\n문의내용\n문의유형\n\n\n\n\n0\ninplace= True 를 사용하는 기준이 존재하는 것인지, 아니면 함수나 메소드...\n코드2\n\n\n1\n참조파일2에 대한 (yolo부분) 답안 파일이 올라오지 않은 것 같습니다!\n시스템 운영\n\n\n2\nAICE 시험 관련하여 이렇게 1대1로 질문하는게 맞나요..?\\n맞다면, 질문드립니...\n시스템 운영\n\n\n3\n예제는 잘 작동한 것 같은데 채점하니 케이스 1만 성공하고 나머지가 fail이 떠 ...\n코드1\n\n\n4\n제주관광공사를 대상으로 관광지 순환 버스 솔루션을 도입하여\\n운전을 못하는 관광객 ...\n이론\n\n\n\n\n\n\n\n- 개행문자(\"\\n\") 삭제\n\ntrain_df[\"문의내용\"] = [i.replace(\"\\n\", \" \") for i in train_df[\"문의내용\"]]",
    "crumbs": [
      "Posts",
      "mini projects",
      "AIVLE",
      "00. 문의 유형 자동분류 모델링 생성"
    ]
  },
  {
    "objectID": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#특수문자-제거",
    "href": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#특수문자-제거",
    "title": "00. 문의 유형 자동분류 모델링 생성",
    "section": "(2) 특수문자 제거",
    "text": "(2) 특수문자 제거\n\nremoval_list =  \"‘, ’, ◇, ‘, ”,  ’, ', ·, \\“, ·, △, ●,  , ■, (, ), \\\", &gt;&gt;, `, /, #, ∼, =,ㆍ&lt;,&gt;, .,?, !,【,】, …, ◆,%, ₩\"\ndef remove_special(sentence: str = None):\n\n    sentence = re.sub(\"[.,\\'\\\"’‘”“!?]\", \"\", sentence)\n    sentence = re.sub(\"[^ㄱ-ㅎ가-힣a-zA-Z\\\\s]\", \" \", sentence)\n    sentence = re.sub(\"\\s+\", \" \", sentence)\n    sentence = sentence.translate(str.maketrans(removal_list, ' '*len(removal_list)))\n    sentence = sentence.strip()\n    sentence = sentence.replace('\\n', ' ')\n\n    return sentence\n\n\ntrain_df[\"특수문자제거\"] = [remove_special(i) for i in train_df[\"문의내용\"]]\ntrain_df[\"특수문자제거\"][:3]\n\n0    inplace True 를 사용하는 기준이 존재하는 것인지 아니면 함수나 메소드에 ...\n1               참조파일 에 대한 yolo부분 답안 파일이 올라오지 않은 것 같습니다\n2    AICE 시험 관련하여 이렇게 대 로 질문하는게 맞나요 맞다면 질문드립니다 구글링이...\nName: 특수문자제거, dtype: object",
    "crumbs": [
      "Posts",
      "mini projects",
      "AIVLE",
      "00. 문의 유형 자동분류 모델링 생성"
    ]
  },
  {
    "objectID": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#단어-분리",
    "href": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#단어-분리",
    "title": "00. 문의 유형 자동분류 모델링 생성",
    "section": "(3) 단어 분리",
    "text": "(3) 단어 분리\n\ntrain_df[\"단어분리\"]= [i.split() for i in train_df[\"특수문자제거\"]]\nprint(train_df[\"단어분리\"][:2])\n\n0    [inplace, True, 를, 사용하는, 기준이, 존재하는, 것인지, 아니면, ...\n1    [참조파일, 에, 대한, yolo부분, 답안, 파일이, 올라오지, 않은, 것, 같습니다]\nName: 단어분리, dtype: object",
    "crumbs": [
      "Posts",
      "mini projects",
      "AIVLE",
      "00. 문의 유형 자동분류 모델링 생성"
    ]
  },
  {
    "objectID": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#조사-인사말-불용어-제거-함수-실행",
    "href": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#조사-인사말-불용어-제거-함수-실행",
    "title": "00. 문의 유형 자동분류 모델링 생성",
    "section": "(4) 조사, 인사말, 불용어 제거 함수 실행",
    "text": "(4) 조사, 인사말, 불용어 제거 함수 실행\n\ndef remove_stopword(sent):\n    stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','을','으로','자','에','와','한','이', '로', '에서', '하는', '하면', '하고', '요', '혹시', '합니다', '감사합니다', '안녕하세요']\n    removed = [word for word in sent if not word in stopwords] # 불용어 제거\n    return removed\n\n\ntrain_df[\"불용어제거\"] = [remove_stopword(i) for i in train_df[\"단어분리\"]]\ntrain_df[\"불용어제거\"].head()\n\n0    [inplace, True, 사용하는, 기준이, 존재하는, 것인지, 아니면, 함수나...\n1       [참조파일, 대한, yolo부분, 답안, 파일이, 올라오지, 않은, 것, 같습니다]\n2    [AICE, 시험, 관련하여, 이렇게, 대, 질문하는게, 맞나요, 맞다면, 질문드립...\n3    [예제는, 작동한, 것, 같은데, 채점하니, 케이스, 만, 성공하고, 나머지가, f...\n4    [제주관광공사를, 대상으로, 관광지, 순환, 버스, 솔루션을, 도입하여, 운전을, ...\nName: 불용어제거, dtype: object",
    "crumbs": [
      "Posts",
      "mini projects",
      "AIVLE",
      "00. 문의 유형 자동분류 모델링 생성"
    ]
  },
  {
    "objectID": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#한글자-단어-제거",
    "href": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#한글자-단어-제거",
    "title": "00. 문의 유형 자동분류 모델링 생성",
    "section": "(5) 한글자 단어 제거",
    "text": "(5) 한글자 단어 제거\n\ntrain_df[\"한글자제거\"] = [[j for j in i if len(j) &gt;=2 ] for i in train_df[\"불용어제거\"]]\ntrain_df[\"한글자제거\"][:5]\n\n0    [inplace, True, 사용하는, 기준이, 존재하는, 것인지, 아니면, 함수나...\n1          [참조파일, 대한, yolo부분, 답안, 파일이, 올라오지, 않은, 같습니다]\n2    [AICE, 시험, 관련하여, 이렇게, 질문하는게, 맞나요, 맞다면, 질문드립니다,...\n3    [예제는, 작동한, 같은데, 채점하니, 케이스, 성공하고, 나머지가, fail이, ...\n4    [제주관광공사를, 대상으로, 관광지, 순환, 버스, 솔루션을, 도입하여, 운전을, ...\nName: 한글자제거, dtype: object",
    "crumbs": [
      "Posts",
      "mini projects",
      "AIVLE",
      "00. 문의 유형 자동분류 모델링 생성"
    ]
  },
  {
    "objectID": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#문장-길이-측정",
    "href": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#문장-길이-측정",
    "title": "00. 문의 유형 자동분류 모델링 생성",
    "section": "(6) 문장 길이 측정",
    "text": "(6) 문장 길이 측정\n\ncleansing_length =[len(i) for i in train_df[\"한글자제거\"]]\ntrain_df[\"cleansing_length\"] = cleansing_length",
    "crumbs": [
      "Posts",
      "mini projects",
      "AIVLE",
      "00. 문의 유형 자동분류 모델링 생성"
    ]
  },
  {
    "objectID": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#문의별-단어-수-시각화",
    "href": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#문의별-단어-수-시각화",
    "title": "00. 문의 유형 자동분류 모델링 생성",
    "section": "(7) 문의별 단어 수 시각화",
    "text": "(7) 문의별 단어 수 시각화\n\ntrain_df.plot(x = \"cleansing_length\", kind = \"hist\",\n                      backend  = \"plotly\", title = \"단어길이 분포\", \n                      height=  500, marginal = \"box\", opacity = 0.6)",
    "crumbs": [
      "Posts",
      "mini projects",
      "AIVLE",
      "00. 문의 유형 자동분류 모델링 생성"
    ]
  },
  {
    "objectID": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#padding-값-설정",
    "href": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#padding-값-설정",
    "title": "00. 문의 유형 자동분류 모델링 생성",
    "section": "(8) padding 값 설정",
    "text": "(8) padding 값 설정\n- 자연어 처리에 입력의 길이를 똑같이 맞추기 위해 데이터의 앞 또는 뒤에 0을 삽입하는 Padding 기법을 적용\n- 적절한 Padding 값을 도출하기 위해 max_length 변수를 생성하고 cleansing_length 변수의 기초통계량 90% 백분위수 값을 할당\n\ntrain_df.cleansing_length.describe()\n\ncount    3032.0000\nmean       30.6781\nstd        40.1747\nmin         1.0000\n25%        12.0000\n50%        21.0000\n75%        36.0000\nmax       735.0000\nName: cleansing_length, dtype: float64\n\n\n- 자연어 처리에 입력의 길이를 똑같이 맞추기 위해 데이터의 앞 또는 뒤에 0을 삽입하는 Padding 기법을 적용\n\nmax_length = train_df.cleansing_length.quantile(.9)\nmax_length\n\n58.0",
    "crumbs": [
      "Posts",
      "mini projects",
      "AIVLE",
      "00. 문의 유형 자동분류 모델링 생성"
    ]
  },
  {
    "objectID": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#단어-모으기",
    "href": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#단어-모으기",
    "title": "00. 문의 유형 자동분류 모델링 생성",
    "section": "(1) 단어 모으기",
    "text": "(1) 단어 모으기\n\nword_list  = [j for i in train_df[\"한글자제거\"] for j in i]\nword_list[:5]\n\n['inplace', 'True', '사용하는', '기준이', '존재하는']",
    "crumbs": [
      "Posts",
      "mini projects",
      "AIVLE",
      "00. 문의 유형 자동분류 모델링 생성"
    ]
  },
  {
    "objectID": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#단어-빈도수-카운트",
    "href": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#단어-빈도수-카운트",
    "title": "00. 문의 유형 자동분류 모델링 생성",
    "section": "(2) 단어 빈도수 카운트",
    "text": "(2) 단어 빈도수 카운트\n\nword_count = Counter(word_list)",
    "crumbs": [
      "Posts",
      "mini projects",
      "AIVLE",
      "00. 문의 유형 자동분류 모델링 생성"
    ]
  },
  {
    "objectID": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#전체-단어-빈도수-및-합계-확인",
    "href": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#전체-단어-빈도수-및-합계-확인",
    "title": "00. 문의 유형 자동분류 모델링 생성",
    "section": "(3) 전체 단어 빈도수 및 합계 확인",
    "text": "(3) 전체 단어 빈도수 및 합계 확인\n\nword_frequency = word_count.values()\ntotal_word = len(set(word_list))\ntotal_frequency_sum = sum(word_count.values())\n\ntotal_word, total_frequency_sum\n\n(23516, 93016)",
    "crumbs": [
      "Posts",
      "mini projects",
      "AIVLE",
      "00. 문의 유형 자동분류 모델링 생성"
    ]
  },
  {
    "objectID": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#희귀-단어-빈도수-및-합계-확인",
    "href": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#희귀-단어-빈도수-및-합계-확인",
    "title": "00. 문의 유형 자동분류 모델링 생성",
    "section": "(4) 희귀 단어 빈도수 및 합계 확인",
    "text": "(4) 희귀 단어 빈도수 및 합계 확인\n\nrare_frequency = { i : j  for i,j in word_count.items() if j ==1}\nrare_count = len(rare_frequency)\nrare_frequency_sum = sum(rare_frequency.values())\n\nrare_count, rare_frequency_sum\n\n(14417, 14417)\n\n\n\n\nCode\nrare_count_percent = rare_count/total_word\nrare_frequency_percent = rare_frequency_sum/total_frequency_sum\n\n\nprint(\"클렌징 데이터의 전체 단어 수: \", total_word)\nprint(\"데이터 내 전체 희귀 단어수: \",  rare_count)\nprint(\"\\n\")\nprint(\"데이터의 전체 단어의 빈도 수 합: \",  total_frequency_sum )\nprint(\"데이터 내 전체 희귀 단어의 빈도 수 합: \",   rare_frequency_sum)\nprint(\"전체 단어에서 희귀 단어가 차지하는 비율: \",  rare_frequency_percent)\n\n\n클렌징 데이터의 전체 단어 수:  23516\n데이터 내 전체 희귀 단어수:  14417\n\n\n데이터의 전체 단어의 빈도 수 합:  93016\n데이터 내 전체 희귀 단어의 빈도 수 합:  14417\n전체 단어에서 희귀 단어가 차지하는 비율:  0.1549948395974886",
    "crumbs": [
      "Posts",
      "mini projects",
      "AIVLE",
      "00. 문의 유형 자동분류 모델링 생성"
    ]
  },
  {
    "objectID": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#단어사전-크기-설정",
    "href": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#단어사전-크기-설정",
    "title": "00. 문의 유형 자동분류 모델링 생성",
    "section": "(5) 단어사전 크기 설정",
    "text": "(5) 단어사전 크기 설정\n- 단어사전크기 = 전체 단어수 - 희귀 단어수\n\nvocab_size = total_word-rare_count\nvocab_size\n\n9099",
    "crumbs": [
      "Posts",
      "mini projects",
      "AIVLE",
      "00. 문의 유형 자동분류 모델링 생성"
    ]
  },
  {
    "objectID": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#단어사전인덱스화-생성",
    "href": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#단어사전인덱스화-생성",
    "title": "00. 문의 유형 자동분류 모델링 생성",
    "section": "(6) 단어사전(인덱스화) 생성",
    "text": "(6) 단어사전(인덱스화) 생성\n\ntokenizer = Tokenizer(num_words = vocab_size)\ntokenizer.fit_on_texts(train_df[\"한글자제거\"])\n\ntrain_df[\"토큰화\"] = tokenizer.texts_to_sequences(train_df[\"한글자제거\"])\n#train_df.head()",
    "crumbs": [
      "Posts",
      "mini projects",
      "AIVLE",
      "00. 문의 유형 자동분류 모델링 생성"
    ]
  },
  {
    "objectID": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#문의유형-데이터-변경",
    "href": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#문의유형-데이터-변경",
    "title": "00. 문의 유형 자동분류 모델링 생성",
    "section": "(1) 문의유형 데이터 변경",
    "text": "(1) 문의유형 데이터 변경\n- data['문의유형'] 값 중 ‘코드1’, ’코드2’는 1로, 그 외 값들은 0으로 변경\n\ntype_dict = {\n    '코드1': 1,\n    '코드2': 1,\n    '웹': 0,\n    '이론': 0,\n    '시스템 운영': 0,\n    '원격': 0\n}\n\ntrain_df[\"문의유형\"] = train_df[\"문의유형\"].map(type_dict)",
    "crumbs": [
      "Posts",
      "mini projects",
      "AIVLE",
      "00. 문의 유형 자동분류 모델링 생성"
    ]
  },
  {
    "objectID": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#ytarget-데이터-분리",
    "href": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#ytarget-데이터-분리",
    "title": "00. 문의 유형 자동분류 모델링 생성",
    "section": "(2) Y(target) 데이터 분리",
    "text": "(2) Y(target) 데이터 분리\n\ny_data =  train_df[\"문의유형\"]",
    "crumbs": [
      "Posts",
      "mini projects",
      "AIVLE",
      "00. 문의 유형 자동분류 모델링 생성"
    ]
  },
  {
    "objectID": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#xfeature-데이터-분리-및-padding-적용",
    "href": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#xfeature-데이터-분리-및-padding-적용",
    "title": "00. 문의 유형 자동분류 모델링 생성",
    "section": "(3) X(Feature) 데이터 분리 및 padding 적용",
    "text": "(3) X(Feature) 데이터 분리 및 padding 적용\n\nx_data = tf.keras.utils.pad_sequences(train_df[\"토큰화\"], maxlen = int(max_length))\n#x_data",
    "crumbs": [
      "Posts",
      "mini projects",
      "AIVLE",
      "00. 문의 유형 자동분류 모델링 생성"
    ]
  },
  {
    "objectID": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#학습-데이터-분리",
    "href": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#학습-데이터-분리",
    "title": "00. 문의 유형 자동분류 모델링 생성",
    "section": "(4) 학습 데이터 분리",
    "text": "(4) 학습 데이터 분리\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size = 0.3, random_state = 2023)",
    "crumbs": [
      "Posts",
      "mini projects",
      "AIVLE",
      "00. 문의 유형 자동분류 모델링 생성"
    ]
  },
  {
    "objectID": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#모델-생성",
    "href": "posts/mini projects/AIVLE/2023-10-16-00. 문의 유형 자동분류 모델링 생성.html#모델-생성",
    "title": "00. 문의 유형 자동분류 모델링 생성",
    "section": "(5) 모델 생성",
    "text": "(5) 모델 생성\n\nimport tensorflow as tf\nfrom keras.layers import *\nfrom keras.models import *\nfrom keras.callbacks import *\nfrom keras.backend import *\nfrom keras.optimizers import *\n\n\na. simple RNN 설계\n\nmodel = Sequential()\nmodel.add(Embedding(input_dim = vocab_size + 1, output_dim = 128, input_length = int(max_length)))\n## input_dim  : 단어 사전의 크기\n## output_dim : 임베딩 차원\n## input_length : 인풋 시퀀스의 길이\n\nmodel.add(SimpleRNN(32))\nmodel.add(Dense(32, activation = \"relu\"))\nmodel.add(Dense(1, activation = \"sigmoid\"))\n\nmodel.compile(loss = tf.keras.losses.binary_crossentropy,\n                optimizer  = tf.keras.optimizers.Adam(0.01) )\n\nmodel.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding (Embedding)       (None, 58, 128)           1164800   \n                                                                 \n simple_rnn (SimpleRNN)      (None, 32)                5152      \n                                                                 \n dense (Dense)               (None, 32)                1056      \n                                                                 \n dense_1 (Dense)             (None, 1)                 33        \n                                                                 \n=================================================================\nTotal params: 1171041 (4.47 MB)\nTrainable params: 1171041 (4.47 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\n\n1. 모델 학습\n\nfrom tensorflow.keras.callbacks import EarlyStopping\nes = EarlyStopping(monitor = \"val_loss\",  ## 과적합 방지 기준\n                                   min_delta = 0, ## 설정한 값으로 변화해야 모델 성능이 개선되었다고 판단하는 기준 ( Threshole)\n                                    patience = 5, ## 성능이 개선되지 않을 떄 얼마나 참을건지\n                                    verbose =1,\n                                    restore_best_weights = True  ## 조기 종료 적용 후 최적 가중치를 모델의 전달\n                                )\n\nmodel.fit(x_train, y_train, epochs = 1000, validation_split = 0.2,\n                batch_size = 32, callbacks = [es])\n\nEpoch 1/1000\n54/54 [==============================] - 2s 19ms/step - loss: 0.6173 - val_loss: 1.7827\nEpoch 2/1000\n54/54 [==============================] - 1s 14ms/step - loss: 0.6140 - val_loss: 0.5381\nEpoch 3/1000\n54/54 [==============================] - 1s 16ms/step - loss: 0.2851 - val_loss: 0.6335\nEpoch 4/1000\n54/54 [==============================] - 1s 15ms/step - loss: 0.1684 - val_loss: 0.9075\nEpoch 5/1000\n54/54 [==============================] - 1s 16ms/step - loss: 0.0913 - val_loss: 1.0009\nEpoch 6/1000\n54/54 [==============================] - 1s 15ms/step - loss: 0.0468 - val_loss: 1.1816\nEpoch 7/1000\n53/54 [============================&gt;.] - ETA: 0s - loss: 0.0275Restoring model weights from the end of the best epoch: 2.\n54/54 [==============================] - 1s 15ms/step - loss: 0.0275 - val_loss: 1.0385\nEpoch 7: early stopping\n\n\n&lt;keras.src.callbacks.History at 0x1b875fb1250&gt;\n\n\n\n\n2. 결과 예측\n\npredicted = model.predict(x_val)\nresult = [1 if np.round(i,1) &gt;=0.5 else 0  for i in predicted ]\n\n29/29 [==============================] - 0s 2ms/step\n\n\n\nprint(confusion_matrix(y_val, result))\nprint(\"\\n\")\nprint(classification_report(y_val, result))\n\n[[445  83]\n [133 249]]\n\n\n              precision    recall  f1-score   support\n\n           0       0.77      0.84      0.80       528\n           1       0.75      0.65      0.70       382\n\n    accuracy                           0.76       910\n   macro avg       0.76      0.75      0.75       910\nweighted avg       0.76      0.76      0.76       910\n\n\n\n\n\n\nb. LSTM 모델 설계\n\nclear_session()\n\nmodel1 = Sequential()\nmodel1.add(Embedding(input_dim = vocab_size + 1, output_dim = 128, input_length = int(max_length)))\nmodel1.add(LSTM(32))\nmodel1.add(Dense(32, activation = \"relu\"))\nmodel1.add(Dense(1, activation = \"sigmoid\"))\n\nmodel1.compile(loss = tf.keras.losses.binary_crossentropy,\n                optimizer  = tf.keras.optimizers.Adam(0.01) )\n\nmodel1.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding (Embedding)       (None, 58, 128)           1164800   \n                                                                 \n lstm (LSTM)                 (None, 32)                20608     \n                                                                 \n dense (Dense)               (None, 32)                1056      \n                                                                 \n dense_1 (Dense)             (None, 1)                 33        \n                                                                 \n=================================================================\nTotal params: 1186497 (4.53 MB)\nTrainable params: 1186497 (4.53 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\n\n1. 모델 학습\n\nhistory1 = model1.fit(x_train, y_train, epochs = 10, validation_split = 0.2,\n                batch_size = 32, verbose = 0).history\n\n\n\n2. 결과 예측\n\nplt.plot(history1[\"loss\"], label = \"train_loss\")\nplt.plot(history1[\"val_loss\"],label = \"val_loss\")\nplt.legend()\n\npredicted1 = model1.predict(x_val)\nresult1 = [1 if np.round(i,1) &gt;=0.5 else 0  for i in predicted1]\n\nprint(confusion_matrix(y_val, result1))\nprint(\"\\n\")\nprint(classification_report(y_val, result1))\n\n29/29 [==============================] - 1s 4ms/step\n[[426 102]\n [ 66 316]]\n\n\n              precision    recall  f1-score   support\n\n           0       0.87      0.81      0.84       528\n           1       0.76      0.83      0.79       382\n\n    accuracy                           0.82       910\n   macro avg       0.81      0.82      0.81       910\nweighted avg       0.82      0.82      0.82       910\n\n\n\n\n\n\n\n\n\n\n\n\n\nc. LSTM 모델 설계 2(+BatchNormalization)\n\nclear_session()\n\nmodel2 = Sequential()\nmodel2.add(Embedding(input_dim = vocab_size + 1, output_dim = 128, input_length = int(max_length)))\nmodel2.add(LSTM(32))\nmodel2.add(BatchNormalization())\nmodel2.add(Dense(32, activation = \"relu\"))\nmodel2.add(BatchNormalization())\nmodel2.add(Dense(1, activation = \"sigmoid\"))\n\nmodel2.compile(loss = tf.keras.losses.binary_crossentropy,\n                optimizer  = tf.keras.optimizers.Adam(0.01) )\n\nmodel2.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding (Embedding)       (None, 58, 128)           1164800   \n                                                                 \n lstm (LSTM)                 (None, 32)                20608     \n                                                                 \n batch_normalization (Batch  (None, 32)                128       \n Normalization)                                                  \n                                                                 \n dense (Dense)               (None, 32)                1056      \n                                                                 \n batch_normalization_1 (Bat  (None, 32)                128       \n chNormalization)                                                \n                                                                 \n dense_1 (Dense)             (None, 1)                 33        \n                                                                 \n=================================================================\nTotal params: 1186753 (4.53 MB)\nTrainable params: 1186625 (4.53 MB)\nNon-trainable params: 128 (512.00 Byte)\n_________________________________________________________________\n\n\n\n1. 모델 학습\n\nhistory2 = model2.fit(x_train, y_train, epochs = 10, validation_split = 0.2,\n                batch_size = 32, verbose = 0).history\n\n\nplt.plot(history2[\"loss\"], label = \"train_loss\")\nplt.plot(history2[\"val_loss\"],label = \"val_loss\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n\n2. 결과 예측\n\npredicted2 = model2.predict(x_val)\nresult2 = [1 if np.round(i,1) &gt;=0.5 else 0  for i in predicted2]\n\nprint(confusion_matrix(y_val, result2))\nprint(\"\\n\")\nprint(classification_report(y_val, result2))\n\n29/29 [==============================] - 1s 4ms/step\n[[437  91]\n [ 83 299]]\n\n\n              precision    recall  f1-score   support\n\n           0       0.84      0.83      0.83       528\n           1       0.77      0.78      0.77       382\n\n    accuracy                           0.81       910\n   macro avg       0.80      0.81      0.80       910\nweighted avg       0.81      0.81      0.81       910\n\n\n\n\n\n\n\nd. BiLSTM 모델 설계\n\nclear_session()\n\nmodel3 = Sequential()\nmodel3.add(Embedding(input_dim = vocab_size + 1, output_dim = 128, input_length = int(max_length)))\nmodel3.add(Dense(1024, activation = \"swish\"))\nmodel3.add(LSTM(32, return_sequences = True))\nmodel3.add(BatchNormalization())\nmodel3.add(GlobalAveragePooling1D())\nmodel3.add(Dense(32, activation = \"swish\"))\nmodel3.add(BatchNormalization())\nmodel3.add(Dense(1, activation = \"sigmoid\"))\n\nmodel3.compile(loss = tf.keras.losses.binary_crossentropy,\n                optimizer  = tf.keras.optimizers.Adam(0.01) )\n\nmodel3.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding (Embedding)       (None, 58, 128)           1164800   \n                                                                 \n dense (Dense)               (None, 58, 1024)          132096    \n                                                                 \n lstm (LSTM)                 (None, 58, 32)            135296    \n                                                                 \n batch_normalization (Batch  (None, 58, 32)            128       \n Normalization)                                                  \n                                                                 \n global_average_pooling1d (  (None, 32)                0         \n GlobalAveragePooling1D)                                         \n                                                                 \n dense_1 (Dense)             (None, 32)                1056      \n                                                                 \n batch_normalization_1 (Bat  (None, 32)                128       \n chNormalization)                                                \n                                                                 \n dense_2 (Dense)             (None, 1)                 33        \n                                                                 \n=================================================================\nTotal params: 1433537 (5.47 MB)\nTrainable params: 1433409 (5.47 MB)\nNon-trainable params: 128 (512.00 Byte)\n_________________________________________________________________\n\n\n\n1. 모델 학습\n\nhistory3 = model3.fit(x_train, y_train, epochs = 10, validation_split = 0.2,\n                                      batch_size = 32, verbose = 1).history\n\nEpoch 1/10\n54/54 [==============================] - 7s 72ms/step - loss: 0.5416 - val_loss: 0.5699\nEpoch 2/10\n54/54 [==============================] - 3s 62ms/step - loss: 0.2478 - val_loss: 0.5226\nEpoch 3/10\n54/54 [==============================] - 3s 62ms/step - loss: 0.1569 - val_loss: 0.6476\nEpoch 4/10\n54/54 [==============================] - 4s 65ms/step - loss: 0.1117 - val_loss: 0.9973\nEpoch 5/10\n54/54 [==============================] - 4s 69ms/step - loss: 0.0901 - val_loss: 0.5806\nEpoch 6/10\n54/54 [==============================] - 3s 62ms/step - loss: 0.0680 - val_loss: 0.6174\nEpoch 7/10\n54/54 [==============================] - 3s 62ms/step - loss: 0.1513 - val_loss: 1.1361\nEpoch 8/10\n54/54 [==============================] - 3s 62ms/step - loss: 0.1202 - val_loss: 2.9996\nEpoch 9/10\n54/54 [==============================] - 3s 62ms/step - loss: 0.1137 - val_loss: 1.2261\nEpoch 10/10\n54/54 [==============================] - 3s 61ms/step - loss: 0.0994 - val_loss: 2.8553\n\n\n\nplt.plot(history3[\"loss\"], label = \"train_loss\")\nplt.plot(history3[\"val_loss\"],label = \"val_loss\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n\n2. 결과 예측\n\npredicted3 = model3.predict(x_val)\nresult3 = [1 if np.round(i,1) &gt;=0.5 else 0  for i in predicted3]\n\nprint(confusion_matrix(y_val, result3))\nprint(\"\\n\")\nprint(classification_report(y_val, result3))\n\n29/29 [==============================] - 1s 17ms/step\n[[527   1]\n [312  70]]\n\n\n              precision    recall  f1-score   support\n\n           0       0.63      1.00      0.77       528\n           1       0.99      0.18      0.31       382\n\n    accuracy                           0.66       910\n   macro avg       0.81      0.59      0.54       910\nweighted avg       0.78      0.66      0.58       910",
    "crumbs": [
      "Posts",
      "mini projects",
      "AIVLE",
      "00. 문의 유형 자동분류 모델링 생성"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Apple/2023-09-26-00. EDA.html",
    "href": "posts/mini projects/Fine Apple/2023-09-26-00. EDA.html",
    "title": "00. EDA",
    "section": "",
    "text": "1 파인애플 보험사의 효괴적인 마케팅 전략을 완성시키기 위한 데이터 기반 마케팅 솔루션 제안\n2 고객별로 특징을 적절하게 반영할 수 있는 군집분석을 통해 고객 segment 개발",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Apple",
      "00. EDA"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Apple/2023-09-26-00. EDA.html#insight",
    "href": "posts/mini projects/Fine Apple/2023-09-26-00. EDA.html#insight",
    "title": "00. EDA",
    "section": "insight",
    "text": "insight\n\n분석가 선정 컬럼을 탐색해본 결과 대부분의 고객들은 중산층에 속해있는 것 같다.\n분석가 선정 컬럼들에 따른 고객 소득 분포의 차이가 유의미하다면 고객 세그먼트와, 데이터 드리븐 전략을 세워 마케팅에 활용할 수 있다.",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Apple",
      "00. EDA"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Apple/2023-09-26-00. EDA.html#insight-1",
    "href": "posts/mini projects/Fine Apple/2023-09-26-00. EDA.html#insight-1",
    "title": "00. EDA",
    "section": "insight",
    "text": "insight\n\n도메인 주용 항목 중 수치형 변수의 분포가 소득을 제외하고 왼쪽으로 치우쳐져 있다.\n소득의 경우 무직, 휴직, False 상태인 고객이 50%정도 차지 하고 있기 때문에 count = 0 부근에서 가장 많은 빈도를 보인다.",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Apple",
      "00. EDA"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Apple/2023-09-26-00. EDA.html#insight-2",
    "href": "posts/mini projects/Fine Apple/2023-09-26-00. EDA.html#insight-2",
    "title": "00. EDA",
    "section": "insight",
    "text": "insight\n\n현재 타 삼품 보유현황은 1, 4이상, 2, 3 순으로 많다.\n상품간 연계되는 서비스를 제공한다면 4이상을 1순위로 올릴 수 있다.",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Apple",
      "00. EDA"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html",
    "title": "00. EDA & Modeling",
    "section": "",
    "text": "1 Fine Watch의 행동 데이터 분류 AI 모델링 요청\n2 출시될 시제품에서 수집한 데이터를 바탕으로 6가지 행동 검토 후 계단오르기를 분류할 수 있는 AI 모델 생성 및 중요도 상위 Feature 선별\n\n6가지 행동 패턴 : STANDING, SITTING, LAYING, WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS\n\n3 데이터 설명\n\nFine Watch 23 시제품에서 수집한 데이터\n가속도 센서 데이터 : 일직선으로 움직이는 물체의 선형가속도를 측정하는 센서 데이터\n자이로스코프 센서 데이터 : 회전하는 물체의 각속도를 측정하는 센서 데이터",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "00. EDA & Modeling"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#feature-데이터-로드",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#feature-데이터-로드",
    "title": "00. EDA & Modeling",
    "section": "(1) feature 데이터 로드",
    "text": "(1) feature 데이터 로드\n\nfeatures = pd.read_csv(\"f.csv\")\nfeatures.head()\n\n\n\n\n\n\n\n\nsensor\nagg\naxis\nfeature_name\n\n\n\n\n0\ntBodyAcc\nmean()\nX\ntBodyAcc-mean()-X\n\n\n1\ntBodyAcc\nmean()\nY\ntBodyAcc-mean()-Y\n\n\n2\ntBodyAcc\nmean()\nZ\ntBodyAcc-mean()-Z\n\n\n3\ntBodyAcc\nstd()\nX\ntBodyAcc-std()-X\n\n\n4\ntBodyAcc\nstd()\nY\ntBodyAcc-std()-Y",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "00. EDA & Modeling"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#고유값-확인",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#고유값-확인",
    "title": "00. EDA & Modeling",
    "section": "(2) 고유값 확인",
    "text": "(2) 고유값 확인\n\nfeatures.sensor.value_counts()\n\nsensor\nfBodyGyro               79\nfBodyAcc                79\nfBodyAccJerk            79\ntBodyAcc                40\ntBodyAccJerk            40\ntBodyGyro               40\ntBodyGyroJerk           40\ntGravityAcc             40\nfBodyBodyGyroJerkMag    13\nfBodyBodyGyroMag        13\nfBodyBodyAccJerkMag     13\nfBodyAccMag             13\ntBodyGyroJerkMag        13\ntBodyGyroMag            13\ntBodyAccJerkMag         13\ntGravityAccMag          13\ntBodyAccMag             13\nangle                    7\nName: count, dtype: int64\n\n\n\nfeatures[\"feature_name\"].value_counts()\n\nfeature_name\nfBodyGyro-bandsEnergy()-25,32    3\nfBodyGyro-bandsEnergy()-49,56    3\nfBodyGyro-bandsEnergy()-25,48    3\nfBodyGyro-bandsEnergy()-1,24     3\nfBodyGyro-bandsEnergy()-49,64    3\n                                ..\ntBodyGyroJerk-min()-X            1\ntBodyGyroJerk-max()-Z            1\ntBodyGyroJerk-max()-Y            1\ntBodyGyroJerk-max()-X            1\nangle(Z,gravityMean)             1\nName: count, Length: 533, dtype: int64\n\n\n\nfeatures[\"agg\"].value_counts()\n\nagg\nbandsEnergy()        126\narCoeff()             60\nmean()                33\nmad()                 33\nmax()                 33\nmin()                 33\nenergy()              33\niqr()                 33\nentropy()             33\nstd()                 33\nsma()                 17\ncorrelation()         15\nmeanFreq()            13\nkurtosis()            13\nskewness()            13\nmaxInds               13\narCoeff()3             5\narCoeff()4             5\narCoeff()2             5\narCoeff()1             5\ntBodyAccMean           1\ntBodyAccJerkMean       1\ntBodyGyroMean          1\ntBodyGyroJerkMean      1\nX                      1\nY                      1\nZ                      1\nName: count, dtype: int64\n\n\n\nfeatures[\"axis\"].value_counts()\n\naxis\nX              76\nY              76\nZ              76\ngravityMean     6\nX,2             5\n               ..\n25,32.1         2\n17,24.1         2\n1,8.1           2\n9,16.1          2\ngravity         1\nName: count, Length: 62, dtype: int64",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "00. EDA & Modeling"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#데이터-셋-나누기",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#데이터-셋-나누기",
    "title": "00. EDA & Modeling",
    "section": "(0) 데이터 셋 나누기",
    "text": "(0) 데이터 셋 나누기\n\ny = data[target]\nx = data.drop(target, axis = 1)\n\nx_train, x_val, y_train, y_val = train_test_split(x,y, test_size = 0.3, random_state = 2023)      \n\n- 각 모델의 비교를 위한 데이터 프레임 생성\n\nmodel_name = []\nvalid_data = []\naccuracy_score = []\nF1_score = []\nresult = pd.DataFrame([model_name,valid_data,accuracy_score,F1_score]).T\nresult.columns = ['model_name', 'valid_data', 'accuracy_score', 'F1_score']\nresult\n\n\n\n\n\n\n\n\nmodel_name\nvalid_data\naccuracy_score\nF1_score",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "00. EDA & Modeling"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#svm",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#svm",
    "title": "00. EDA & Modeling",
    "section": "(1) SVM",
    "text": "(1) SVM\n\nfrom sklearn.svm import SVC\n\n\nsvc_model = SVC(random_state  = 2023)\nsvc_model.fit(x_train, y_train)\nsvc_pred = svc_model.predict(x_val)\n#svc_pred",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "00. EDA & Modeling"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#logistic",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#logistic",
    "title": "00. EDA & Modeling",
    "section": "(2) Logistic",
    "text": "(2) Logistic\n\nfrom sklearn.linear_model import LogisticRegression\n\nlr_model = LogisticRegression(random_state=2023)\nlr_model.fit(x_train, y_train)\nlr_pred = lr_model.predict(x_val)\n\nC:\\Users\\rkdcj\\anaconda3\\envs\\dx\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning:\n\nlbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n\n\n\n\nresult.loc[1,:] = ['lr', 'train', np.mean(y_val == lr_pred), f1_score(y_val,lr_pred, average = \"macro\")]\nresult\n\n\n\n\n\n\n\n\nmodel_name\nvalid_data\naccuracy_score\nF1_score\n\n\n\n\n1\nlr\ntrain\n0.984136\n0.985601",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "00. EDA & Modeling"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#knn",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#knn",
    "title": "00. EDA & Modeling",
    "section": "(3) KNN",
    "text": "(3) KNN\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\n\nknn_model = KNeighborsClassifier(n_neighbors=3)\nknn_model.fit(x_train, y_train)\nknn_pred = knn_model.predict(x_val)\n\n\nresult.loc[2] = [\"knn\",\"train\",np.mean(knn_pred == y_val), f1_score(y_val,knn_pred, average = \"macro\")] \nresult\n\n\n\n\n\n\n\n\nmodel_name\nvalid_data\naccuracy_score\nF1_score\n\n\n\n\n1\nlr\ntrain\n0.984136\n0.985601\n\n\n2\nknn\ntrain\n0.954674\n0.958345",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "00. EDA & Modeling"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#gbm",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#gbm",
    "title": "00. EDA & Modeling",
    "section": "(4) GBM",
    "text": "(4) GBM\n\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n\ngbc_model = GradientBoostingClassifier(random_state = 2023)\ngbc_model.fit(x_train,y_train)\ngbc_pred = gbc_model.predict(x_val)\n\n\nresult.loc[3] = [\"gbc\",\"train\",np.mean(gbc_pred == y_val), f1_score(y_val, gbc_pred, average = \"macro\")]\nresult\n\n\n\n\n\n\n\n\nmodel_name\nvalid_data\naccuracy_score\nF1_score\n\n\n\n\n1\nlr\ntrain\n0.984136\n0.985601\n\n\n2\nknn\ntrain\n0.954674\n0.958345\n\n\n3\ngbc\ntrain\n0.981870\n0.983141",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "00. EDA & Modeling"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#xgb",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#xgb",
    "title": "00. EDA & Modeling",
    "section": "(5) XGB",
    "text": "(5) XGB\n\nfrom xgboost import XGBClassifier\n\ndic = {'LAYING' : 2,\n 'SITTING' : 1,\n 'STANDING' : 0,\n 'WALKING' : 3,\n 'WALKING_DOWNSTAIRS' : 4,\n 'WALKING_UPSTAIRS': 5}\n\ny_train_map = [dic[i] for i in y_train]\ny_val_map =  [dic[i] for i in y_val]                                                                     \n\n\nxgb_model = XGBClassifier(learning_rate=0.2, max_depth=2, random_state=2023)\n\nxgb_model.fit(x_train,y_train_map)\n\nxgb_pred = xgb_model.predict(x_val)\n\nresult.loc[5] =  [\"xgb\", \"train\", np.mean(xgb_pred == y_val_map), f1_score(y_val_map, xgb_pred, average = \"macro\")]\nresult\n\n\n\n\n\n\n\n\nmodel_name\nvalid_data\naccuracy_score\nF1_score\n\n\n\n\n1\nlr\ntrain\n0.984136\n0.985601\n\n\n2\nknn\ntrain\n0.954674\n0.958345\n\n\n3\ngbc\ntrain\n0.981870\n0.983141\n\n\n5\nxgb\ntrain\n0.990368\n0.991178",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "00. EDA & Modeling"
    ]
  }
]