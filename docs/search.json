[
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html",
    "title": "01. model tuning & save",
    "section": "",
    "text": "1 모델링 결과 XGB 모델을 적합했을 경우 가장 예측 성능이 좋았음\n2 Hyperparameter tuning 기법과 Selection 기법을 사용해 최종 모델링 수행\n\nHyperparameter Tuning: AI 모델 학습시 매개변수를 조정하여 최상의 성능을 발휘하는 매개변수를 찾는 기법\nFeature Selection: 모델링 시 raw data의 562개나 되는 모든 feature를 사용하는 것은 computing power와 memory 측면에서 매우 비효율적이기 때문에 결과 예측에 영향도가 높은 중요 feature만 선택하여 자원을 절약하고 모델의 성능을 높이는 기법",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "01. model tuning & save"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#라이브러리-호출",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#라이브러리-호출",
    "title": "01. model tuning & save",
    "section": "(1) 라이브러리 호출",
    "text": "(1) 라이브러리 호출\n\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "01. model tuning & save"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#xy-데이터-나누기",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#xy-데이터-나누기",
    "title": "01. model tuning & save",
    "section": "(2) X,y 데이터 나누기",
    "text": "(2) X,y 데이터 나누기\n\ntarget = \"Activity\"\n\nx = data.drop(target, axis = 1)\ny = data[target]",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "01. model tuning & save"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#encoding",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#encoding",
    "title": "01. model tuning & save",
    "section": "(3) Encoding",
    "text": "(3) Encoding\n\ndic = {'STANDING':0, 'SITTING':1, 'LAYING':2, 'WALKING':3, 'WALKING_UPSTAIRS':4, 'WALKING_DOWNSTAIRS':5}\ny_map = [dic[i] for i in y]\ny_map[:5]\n\n[0, 2, 0, 3, 5]",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "01. model tuning & save"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#train-test-data-분리",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#train-test-data-분리",
    "title": "01. model tuning & save",
    "section": "(4) train, test data 분리",
    "text": "(4) train, test data 분리\n\nx_train, x_val, y_train, y_val = train_test_split(x, y_map, random_state = 2023, test_size = 0.3)",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "01. model tuning & save"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#최적의-hyperparameter-찾기",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#최적의-hyperparameter-찾기",
    "title": "01. model tuning & save",
    "section": "(5) 최적의 Hyperparameter 찾기",
    "text": "(5) 최적의 Hyperparameter 찾기\n\nparams = {'learning_rate': [0.1, 0.2, 0.3], 'max_depth': [2, 3, 4]}\nxgb_model = XGBClassifier(random_state = 2023 )\n\nhpt_xgb_model = GridSearchCV(estimator= xgb_model , param_grid= params, cv=3, verbose=2)\n\nhpt_xgb_model.fit(x_train, y_train)\n\nhpt_xgb_pred = hpt_xgb_model.predict(x_val)\n\nFitting 3 folds for each of 9 candidates, totalling 27 fits\n[CV] END .....................learning_rate=0.1, max_depth=2; total time=   6.6s\n[CV] END .....................learning_rate=0.1, max_depth=2; total time=   6.8s\n[CV] END .....................learning_rate=0.1, max_depth=2; total time=   6.8s\n[CV] END .....................learning_rate=0.1, max_depth=3; total time=   9.1s\n[CV] END .....................learning_rate=0.1, max_depth=3; total time=   9.3s\n[CV] END .....................learning_rate=0.1, max_depth=3; total time=   9.5s\n[CV] END .....................learning_rate=0.1, max_depth=4; total time=  11.8s\n[CV] END .....................learning_rate=0.1, max_depth=4; total time=  11.9s\n[CV] END .....................learning_rate=0.1, max_depth=4; total time=  12.2s\n[CV] END .....................learning_rate=0.2, max_depth=2; total time=   7.2s\n[CV] END .....................learning_rate=0.2, max_depth=2; total time=   7.4s\n[CV] END .....................learning_rate=0.2, max_depth=2; total time=   7.3s\n[CV] END .....................learning_rate=0.2, max_depth=3; total time=   8.8s\n[CV] END .....................learning_rate=0.2, max_depth=3; total time=   8.8s\n[CV] END .....................learning_rate=0.2, max_depth=3; total time=   9.4s\n[CV] END .....................learning_rate=0.2, max_depth=4; total time=  10.3s\n[CV] END .....................learning_rate=0.2, max_depth=4; total time=  10.1s\n[CV] END .....................learning_rate=0.2, max_depth=4; total time=   9.8s\n[CV] END .....................learning_rate=0.3, max_depth=2; total time=   7.1s\n[CV] END .....................learning_rate=0.3, max_depth=2; total time=   6.8s\n[CV] END .....................learning_rate=0.3, max_depth=2; total time=   6.9s\n[CV] END .....................learning_rate=0.3, max_depth=3; total time=   8.0s\n[CV] END .....................learning_rate=0.3, max_depth=3; total time=   8.0s\n[CV] END .....................learning_rate=0.3, max_depth=3; total time=   7.9s\n[CV] END .....................learning_rate=0.3, max_depth=4; total time=   8.6s\n[CV] END .....................learning_rate=0.3, max_depth=4; total time=   8.6s\n[CV] END .....................learning_rate=0.3, max_depth=4; total time=   8.9s",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "01. model tuning & save"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#결과-확인-및-저장",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#결과-확인-및-저장",
    "title": "01. model tuning & save",
    "section": "(6) 결과 확인 및 저장",
    "text": "(6) 결과 확인 및 저장\n- 최적의 파라미터 확인\n\nparams = hpt_xgb_model.best_params_\nparams\n\n{'learning_rate': 0.3, 'max_depth': 2}\n\n\n- 정확도 확인\n\naccuracy_score(y_val,hpt_xgb_pred)\n\n0.9920679886685553\n\n\n\nhpt_xgb_model = XGBClassifier(learning_rate=0.3, max_depth = 2,random_state=2023)\nhpt_xgb_model.fit(x_train,y_train)\nhpt_xgb_pred = hpt_xgb_model.predict(x_val)\nhpt_xgb_pred\n\narray([3, 0, 2, ..., 3, 3, 2], dtype=int64)\n\n\n\nresult.loc[5] = [\"hpt_xgb\", \"train\", \n                 accuracy_score(y_val, hpt_xgb_pred), \n                 f1_score(y_val, hpt_xgb_pred, average = \"macro\")]\nresult\n\n\n\n\n\n\n\n\nmodel_name\nvalid_data\naccuracy_score\nF1_score\n\n\n\n\n0\nlr\ntrain\n0.984136\n0.985601\n\n\n1\nknn\ntrain\n0.954674\n0.958345\n\n\n2\ngbc\ntrain\n0.981870\n0.983141\n\n\n3\nxgb\ntrain\n0.990368\n0.991178\n\n\n5\nhpt_xgb\ntrain\n0.992068\n0.992707",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "01. model tuning & save"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#변수-중요도-산출",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#변수-중요도-산출",
    "title": "01. model tuning & save",
    "section": "(1) 변수 중요도 산출",
    "text": "(1) 변수 중요도 산출\n\nimp = hpt_xgb_model.feature_importances_\nf_name = hpt_xgb_model.feature_names_in_\n\n\nimportance_sort = pd.DataFrame({\"feature_name\" : f_name, \n                                \"feature_importance\" : imp})\nimportance_sort.head()\n\n\n\n\n\n\n\n\nfeature_name\nfeature_importance\n\n\n\n\n0\ntBodyAcc-mean()-X\n0.000000\n\n\n1\ntBodyAcc-mean()-Y\n0.000721\n\n\n2\ntBodyAcc-mean()-Z\n0.000000\n\n\n3\ntBodyAcc-std()-X\n0.000366\n\n\n4\ntBodyAcc-std()-Y\n0.000000\n\n\n\n\n\n\n\n\nimportance_sort.sort_values(\"feature_importance\", ascending = False, inplace = True)\nimportance_sort.head()\n\n\n\n\n\n\n\n\nfeature_name\nfeature_importance\n\n\n\n\n558\nangle(X,gravityMean)\n0.114671\n\n\n201\ntBodyAccMag-std()\n0.101686\n\n\n296\nfBodyAcc-skewness()-X\n0.065176\n\n\n503\nfBodyAccMag-std()\n0.042554\n\n\n73\ntGravityAcc-arCoeff()-Z,1\n0.040255\n\n\n\n\n\n\n\n\nimportance_sort.reset_index(drop = True, inplace = True)\n#importance_sort",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "01. model tuning & save"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#중요-feature-150개-선정",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#중요-feature-150개-선정",
    "title": "01. model tuning & save",
    "section": "(2) 중요 feature 150개 선정",
    "text": "(2) 중요 feature 150개 선정\n\nimportance_150 = importance_sort[\"feature_name\"][:150]\nimportance_150.head()\n\n0         angle(X,gravityMean)\n1            tBodyAccMag-std()\n2        fBodyAcc-skewness()-X\n3            fBodyAccMag-std()\n4    tGravityAcc-arCoeff()-Z,1\nName: feature_name, dtype: object\n\n\n\nx_train_150 = x_train[importance_150]\nx_val_150 = x_val[importance_150]\n\n\na. 모델링\n\nhpt_xgb_150_model = XGBClassifier(params, random_state = 2023)\nhpt_xgb_150_model.fit(x_train_150,y_train)\nhpt_xgb_150_pred = hpt_xgb_150_model.predict(x_val_150)\nhpt_xgb_150_pred\n\nC:\\Users\\rkdcj\\anaconda3\\envs\\dx\\Lib\\site-packages\\xgboost\\core.py:726: FutureWarning:\n\nPass `objective` as keyword args.\n\n\n\narray([3, 0, 2, ..., 3, 3, 2], dtype=int64)\n\n\n\n\nb. 예측 성능 결과 저장\n\nresult.loc[7] = [\"hpt_xgb_150\", \"train\", \n             accuracy_score(y_val,hpt_xgb_150_pred),\n             f1_score(y_val, hpt_xgb_150_pred, average = \"macro\")]\n\n\nresult\n\n\n\n\n\n\n\n\nmodel_name\nvalid_data\naccuracy_score\nF1_score\n\n\n\n\n0\nlr\ntrain\n0.984136\n0.985601\n\n\n1\nknn\ntrain\n0.954674\n0.958345\n\n\n2\ngbc\ntrain\n0.981870\n0.983141\n\n\n3\nxgb\ntrain\n0.990368\n0.991178\n\n\n5\nhpt_xgb\ntrain\n0.992068\n0.992707\n\n\n7\nhpt_xgb_150\ntrain\n0.989235\n0.989286",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "01. model tuning & save"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#중요-feature-50개-선정",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#중요-feature-50개-선정",
    "title": "01. model tuning & save",
    "section": "(3) 중요 feature 50개 선정",
    "text": "(3) 중요 feature 50개 선정\n\nimportance_50 = importance_150[:50]\nimportance_50.head()\n\n0         angle(X,gravityMean)\n1            tBodyAccMag-std()\n2        fBodyAcc-skewness()-X\n3            fBodyAccMag-std()\n4    tGravityAcc-arCoeff()-Z,1\nName: feature_name, dtype: object\n\n\n\na. 모델링\n\nx_train_50 = x_train[importance_50]\nx_val_50 = x_val[importance_50]\n\n\nhpt_xgb_50_model = XGBClassifier(params, random_stat = 2023)\nhpt_xgb_50_model.fit(x_train_50, y_train)\nhpt_xgb_50_pred = hpt_xgb_50_model.predict(x_val_50)\nhpt_xgb_50_pred\n\nC:\\Users\\rkdcj\\anaconda3\\envs\\dx\\Lib\\site-packages\\xgboost\\core.py:726: FutureWarning:\n\nPass `objective` as keyword args.\n\nC:\\Users\\rkdcj\\anaconda3\\envs\\dx\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning:\n\n[17:47:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \nParameters: { \"random_stat\" } are not used.\n\n\n\n\narray([3, 0, 2, ..., 3, 3, 2], dtype=int64)\n\n\n\n\nb. 예측 성능 결과 저장\n\nresult.loc[8] = [\"hpt_xgb_50\", \"train\", \n             accuracy_score(y_val,hpt_xgb_50_pred),\n             f1_score(y_val, hpt_xgb_50_pred, average = \"macro\")]\n\n\nresult\n\n\n\n\n\n\n\n\nmodel_name\nvalid_data\naccuracy_score\nF1_score\n\n\n\n\n0\nlr\ntrain\n0.984136\n0.985601\n\n\n1\nknn\ntrain\n0.954674\n0.958345\n\n\n2\ngbc\ntrain\n0.981870\n0.983141\n\n\n3\nxgb\ntrain\n0.990368\n0.991178\n\n\n5\nhpt_xgb\ntrain\n0.992068\n0.992707\n\n\n7\nhpt_xgb_150\ntrain\n0.989235\n0.989286\n\n\n8\nhpt_xgb_50\ntrain\n0.988102\n0.988090",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "01. model tuning & save"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#결과-시각화",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#결과-시각화",
    "title": "01. model tuning & save",
    "section": "(4) 결과 시각화",
    "text": "(4) 결과 시각화\n\nresult.melt(id_vars = [\"model_name\"], \n            value_vars= [\"accuracy_score\", \"F1_score\"])\n\n\n\n\n\n\n\n\nmodel_name\nvariable\nvalue\n\n\n\n\n0\nlr\naccuracy_score\n0.984136\n\n\n1\nknn\naccuracy_score\n0.954674\n\n\n2\ngbc\naccuracy_score\n0.981870\n\n\n3\nxgb\naccuracy_score\n0.990368\n\n\n4\nhpt_xgb\naccuracy_score\n0.992068\n\n\n5\nhpt_xgb_150\naccuracy_score\n0.989235\n\n\n6\nhpt_xgb_50\naccuracy_score\n0.988102\n\n\n7\nlr\nF1_score\n0.985601\n\n\n8\nknn\nF1_score\n0.958345\n\n\n9\ngbc\nF1_score\n0.983141\n\n\n10\nxgb\nF1_score\n0.991178\n\n\n11\nhpt_xgb\nF1_score\n0.992707\n\n\n12\nhpt_xgb_150\nF1_score\n0.989286\n\n\n13\nhpt_xgb_50\nF1_score\n0.988090\n\n\n\n\n\n\n\n\nfig = result.melt(id_vars = [\"model_name\"], \n            value_vars= [\"accuracy_score\", \"F1_score\"]).\\\n                plot(x = \"variable\", y = \"value\", \n                     color = \"variable\", kind = \"bar\", \n                     backend = \"plotly\", facet_col = \"model_name\", facet_col_wrap = 4,\n                     width = 1200, height = 800)\n\nfig.update_yaxes(range = (0.95, 1.0))",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "01. model tuning & save"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#model-save",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00. model tuning, save.html#model-save",
    "title": "01. model tuning & save",
    "section": "(5) model save",
    "text": "(5) model save\n- 최적의 성능을 보인 모델저장\n\nhpt_xgb 모델저장\n\n\nimport joblib\n\njoblib.dump(hpt_xgb_model, \"hpt_xgb_top_model.pkl\")\n\n['hpt_xgb_top_model.pkl']\n\n\n\n저장한 모델 로드\n\n\nfinal_model = joblib.load(\"hpt_xgb_top_model.pkl\")\n\n\n예측결과 저장\n\n\nfinal_pred = final_model.predict(x_val)\n\n\ndic.items()\n\ndict_items([('STANDING', 0), ('SITTING', 1), ('LAYING', 2), ('WALKING', 3), ('WALKING_UPSTAIRS', 4), ('WALKING_DOWNSTAIRS', 5)])\n\n\n\ndic_reverse = {j : i for i,j in dic.items()}\n\n\npd.Series(final_pred).map(dic_reverse).to_csv(\"final_predict.csv\", index = False)",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "01. model tuning & save"
    ]
  },
  {
    "objectID": "posts/2023-07-31-00.intro.html",
    "href": "posts/2023-07-31-00.intro.html",
    "title": "00. quarto blog",
    "section": "",
    "text": "- 어… 일단 평소에도 quarto를 이용해서 웹사이트를 관리했지만… 뭔가 처음 깃허브를 접하구 하시는 분들은 이 플랫폼을 사용할 때 되게 난항이 있을것 같다… (내가 그랬다…)\n- 그리고 원래 만들어 놓았던 사이트는 뭔가 좀 지저분한 느낌이 들어서….\n- 에이블스쿨 하면서 배운것들 기록할 때는 뭔가 깔끔한 공간에 하고 싶기도 하다.\n- 이참에 절차를 확실히 내가 적어두자!\n\n\n- quarto download link : 여기서 quarto를 다운받자!\n\n\n\n- Terminal을 켠다음에 아래와 같은 명령어를 입력한다!\n(그.. 명령어 입력할 때 현재 자기 주피터 킬때 켜지는 폴더로 옮긴 다음에 수행하자… 골치 아프다ㅜㅜ)\nquarto create project website gcsite\n- 그러면 다음과 같은 이미지가 보인다\n\n- 저기 open with 어찌고 보이는데 d버튼 누르면 (don’t open)으로 넘어가니 그걸 선택한 후 엔터를 눌러준다!\n- 그러면 아래 이미지처럼 맨 밑에 gcsite라는 폴더가 생긴 것을 볼 수 있다.\n\n\n\n\n- git bash 쓰는 사람들 많던데 난 github desktop이 훨씬 편하다.\n- git 알못이기 때문에 많은 것을 알기 위해 괴롭고 싶지 않다.\n- 뭐 여튼 깃허브 데스크탑을 킨다.\n- 상단 메뉴바 \\(\\to\\) File \\(\\to\\) Add local repository\n- 그러면 아래와 같은 경고문이 뜬다.\n\n- local하고 연결하고 싶은데 깃허브에는 gcsite가 없으니 대충 만들어 달라는 것임 “create a repository” 를 눌러주자.\n\n- 무시, 걍 create repository ㄱㄱ\n- 그러면 깃허브 데스크탑에서 너 방금 만든거 너꺼 깃허브에 Publish 할거냐고 물어봄\n\n- Publish repository 눌러주면 끝~~ (단, publish할 때 private 체크박스는 해제하구 하자!)\n- 그 다음 내가 생성산 gcsite 저장소 setting으로 넘어가서 pages를 클릭!\n- 아래와 같이 branch를 수정 후 save 버튼 눌러주자\n\n\n\n\n- quarto 원리 : 작성한 ipynb파일 html파일로 출력해서 그 html파일들로 웹사이트를 구성하는 것1\n- step1. posts와 docs라는 폴더를 만들자\n\nposts는 내가 작성하는 ipynb파일들이 들어갈거고, docs에는 html파일이 들어갈 것이다.\n\n- step2. index 파일 수정\n\nindex파일은 뭐랄까 네비게이터 역할이랄까 아래와 같이 바꿔주자\n\n---\ntitle: \"GC site\"\nlisting:\n  contents: posts\n  sort: [date desc, title]\n  type: table\n  categories: true\n  sort-ui: true\n  filter-ui: true\npage-layout: full\ntitle-block-banner: true\n---\n- step3. _quarto.uml 파일 수정 \\(\\to\\) 템플릿이랑 디자인 이쁜거 많으니 본인 입맛에 맞게 수정하면 됩니당\nproject:\n  type: website\n  output-dir : docs  \nwebsite:\n  title: \"GC site\"\n  page-navigation: true\n  navbar:\n    right:\n      - icon : github\n        href : https://github.com/gangcheol/\n  sidebar:\n    style: \"docked\"\n    search: True\n    contents: auto\n    \nformat:\n  html:\n    css: styles.css\n    toc: true\n    code-fold : False\n    code-line-numbers : True\n    code-copy : True\n\ntheme :\n  light : flatly\n  \neditor : visual\n- step4. 앞서 만든 posts폴더에 아무 파일이나 만들어보자\n\n- step5. 그 후 다시 터미널에서 내가 생성한 폴더로 이동\n필자의 경우는 cd gcsite\n- step6. quarto render 입력\n- step7. github desktop보면 난리가 났을 것이다. 막 일을 좀 많이 했음.\n\n로컬하고 연결되어 있으니 로컬이 하고 있는 걸 다적어서 그럼\n\n\n\n저기 내가 밑에 이러한 기록을 init이라고 써놨다. 저건 내가 로컬에서 한 행동을 내 깃허브 로컬에 저장할 건데, 그 행동을 init이라고 쓴거\n이제 저 Commit to main 버튼을 눌러주고 가운데 화면에 뜨는 push origin을 눌러주자!\n\n- 마지막!! 아까 깃허브 로컬 셋팅에서 pases란에 잠시 후에 들어가보면 다음과 같은 것을 볼 수 있다.\n\n- 저 링크로 들어가면 내가 만든 웹사이트 초안을 볼 수 있다.\n- 링크",
    "crumbs": [
      "Posts",
      "00. quarto blog"
    ]
  },
  {
    "objectID": "posts/2023-07-31-00.intro.html#install",
    "href": "posts/2023-07-31-00.intro.html#install",
    "title": "00. quarto blog",
    "section": "",
    "text": "- quarto download link : 여기서 quarto를 다운받자!",
    "crumbs": [
      "Posts",
      "00. quarto blog"
    ]
  },
  {
    "objectID": "posts/2023-07-31-00.intro.html#website-생성",
    "href": "posts/2023-07-31-00.intro.html#website-생성",
    "title": "00. quarto blog",
    "section": "",
    "text": "- Terminal을 켠다음에 아래와 같은 명령어를 입력한다!\n(그.. 명령어 입력할 때 현재 자기 주피터 킬때 켜지는 폴더로 옮긴 다음에 수행하자… 골치 아프다ㅜㅜ)\nquarto create project website gcsite\n- 그러면 다음과 같은 이미지가 보인다\n\n- 저기 open with 어찌고 보이는데 d버튼 누르면 (don’t open)으로 넘어가니 그걸 선택한 후 엔터를 눌러준다!\n- 그러면 아래 이미지처럼 맨 밑에 gcsite라는 폴더가 생긴 것을 볼 수 있다.",
    "crumbs": [
      "Posts",
      "00. quarto blog"
    ]
  },
  {
    "objectID": "posts/2023-07-31-00.intro.html#깃허브-로컬-연결",
    "href": "posts/2023-07-31-00.intro.html#깃허브-로컬-연결",
    "title": "00. quarto blog",
    "section": "",
    "text": "- git bash 쓰는 사람들 많던데 난 github desktop이 훨씬 편하다.\n- git 알못이기 때문에 많은 것을 알기 위해 괴롭고 싶지 않다.\n- 뭐 여튼 깃허브 데스크탑을 킨다.\n- 상단 메뉴바 \\(\\to\\) File \\(\\to\\) Add local repository\n- 그러면 아래와 같은 경고문이 뜬다.\n\n- local하고 연결하고 싶은데 깃허브에는 gcsite가 없으니 대충 만들어 달라는 것임 “create a repository” 를 눌러주자.\n\n- 무시, 걍 create repository ㄱㄱ\n- 그러면 깃허브 데스크탑에서 너 방금 만든거 너꺼 깃허브에 Publish 할거냐고 물어봄\n\n- Publish repository 눌러주면 끝~~ (단, publish할 때 private 체크박스는 해제하구 하자!)\n- 그 다음 내가 생성산 gcsite 저장소 setting으로 넘어가서 pages를 클릭!\n- 아래와 같이 branch를 수정 후 save 버튼 눌러주자",
    "crumbs": [
      "Posts",
      "00. quarto blog"
    ]
  },
  {
    "objectID": "posts/2023-07-31-00.intro.html#문서-생성",
    "href": "posts/2023-07-31-00.intro.html#문서-생성",
    "title": "00. quarto blog",
    "section": "",
    "text": "- quarto 원리 : 작성한 ipynb파일 html파일로 출력해서 그 html파일들로 웹사이트를 구성하는 것1\n- step1. posts와 docs라는 폴더를 만들자\n\nposts는 내가 작성하는 ipynb파일들이 들어갈거고, docs에는 html파일이 들어갈 것이다.\n\n- step2. index 파일 수정\n\nindex파일은 뭐랄까 네비게이터 역할이랄까 아래와 같이 바꿔주자\n\n---\ntitle: \"GC site\"\nlisting:\n  contents: posts\n  sort: [date desc, title]\n  type: table\n  categories: true\n  sort-ui: true\n  filter-ui: true\npage-layout: full\ntitle-block-banner: true\n---\n- step3. _quarto.uml 파일 수정 \\(\\to\\) 템플릿이랑 디자인 이쁜거 많으니 본인 입맛에 맞게 수정하면 됩니당\nproject:\n  type: website\n  output-dir : docs  \nwebsite:\n  title: \"GC site\"\n  page-navigation: true\n  navbar:\n    right:\n      - icon : github\n        href : https://github.com/gangcheol/\n  sidebar:\n    style: \"docked\"\n    search: True\n    contents: auto\n    \nformat:\n  html:\n    css: styles.css\n    toc: true\n    code-fold : False\n    code-line-numbers : True\n    code-copy : True\n\ntheme :\n  light : flatly\n  \neditor : visual\n- step4. 앞서 만든 posts폴더에 아무 파일이나 만들어보자\n\n- step5. 그 후 다시 터미널에서 내가 생성한 폴더로 이동\n필자의 경우는 cd gcsite\n- step6. quarto render 입력\n- step7. github desktop보면 난리가 났을 것이다. 막 일을 좀 많이 했음.\n\n로컬하고 연결되어 있으니 로컬이 하고 있는 걸 다적어서 그럼\n\n\n\n저기 내가 밑에 이러한 기록을 init이라고 써놨다. 저건 내가 로컬에서 한 행동을 내 깃허브 로컬에 저장할 건데, 그 행동을 init이라고 쓴거\n이제 저 Commit to main 버튼을 눌러주고 가운데 화면에 뜨는 push origin을 눌러주자!\n\n- 마지막!! 아까 깃허브 로컬 셋팅에서 pases란에 잠시 후에 들어가보면 다음과 같은 것을 볼 수 있다.\n\n- 저 링크로 들어가면 내가 만든 웹사이트 초안을 볼 수 있다.\n- 링크",
    "crumbs": [
      "Posts",
      "00. quarto blog"
    ]
  },
  {
    "objectID": "about.html#contact",
    "href": "about.html#contact",
    "title": "About me",
    "section": "contact",
    "text": "contact\n\nE-mail : rkdcjf8232@gmail.com",
    "crumbs": [
      "**About me**"
    ]
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About me",
    "section": "Education",
    "text": "Education\n\n전북대학교 통계학 학사(부전공 : 컴퓨터공학) | 2015.03 ~ 2021.02\n전북대학교 통계학 석사 | 2021.03 ~ 2023.02",
    "crumbs": [
      "**About me**"
    ]
  },
  {
    "objectID": "about.html#certificate",
    "href": "about.html#certificate",
    "title": "About me",
    "section": "Certificate",
    "text": "Certificate\n\n사회조사분석사 2급\n데이터분석준전문가(ADsP)\nAICE Associate",
    "crumbs": [
      "**About me**"
    ]
  },
  {
    "objectID": "about.html#skill",
    "href": "about.html#skill",
    "title": "About me",
    "section": "Skill",
    "text": "Skill\n\nR ⭐⭐⭐⭐\nPython ⭐⭐⭐⭐\nEXCEL ⭐⭐⭐⭐\nSPSS ⭐⭐⭐⭐\nSQL ⭐⭐⭐\nJAVA, C ⭐⭐",
    "crumbs": [
      "**About me**"
    ]
  },
  {
    "objectID": "about.html#extracurricular-activities",
    "href": "about.html#extracurricular-activities",
    "title": "About me",
    "section": "Extracurricular Activities",
    "text": "Extracurricular Activities\n\n국민연금공단 빅데이터부 현장실습 | 2020. 03 ~ 2020. 06\n지역 문화산업 융복합 데이터 전문가 과정 | 과학기술정보통신부, 한국데이터산업진흥원 | 2021. 06 ~ 2021. 08\n빅데이터 혁신공유대학사업 서포터즈 |전북대학교 빅데이터 현신공유대학사업| 2021. 07. 01 ~ 2021. 10. 31\nKT AIVLE School DX Consultant Track | KT | 2023. 08. 08 ~ 2024. 01. 25",
    "crumbs": [
      "**About me**"
    ]
  },
  {
    "objectID": "about.html#publication",
    "href": "about.html#publication",
    "title": "About me",
    "section": "Publication",
    "text": "Publication\n\n데이터 분석을 통한 지역별 고령친화도 시각화\n\n김영선, 강민구, 이강철 등 | 문화융복합아카이빙연구소 | 2021. 10 | 기록관리/보존\n\n핵심어 추출 및 데이터 증강기법을 이용한 텍스트 분류 모델 성능 개선\n\n이강철, 안정용 | 한국자료분석학회 | 한국자료분석학회 | 2022. 10 | 통계학",
    "crumbs": [
      "**About me**"
    ]
  },
  {
    "objectID": "about.html#awards",
    "href": "about.html#awards",
    "title": "About me",
    "section": "Awards",
    "text": "Awards\n\n학회장상 | 한국통계학회 | 2023. 02. 22\nAIVLE Big Project Practical | KT | 2024. 01. 25",
    "crumbs": [
      "**About me**"
    ]
  },
  {
    "objectID": "about.html#interest",
    "href": "about.html#interest",
    "title": "About me",
    "section": "Interest",
    "text": "Interest\n\nNLP\nAction Recognition, Object Detection\nData Science\nGrowth Hacking",
    "crumbs": [
      "**About me**"
    ]
  },
  {
    "objectID": "about.html#my-blog",
    "href": "about.html#my-blog",
    "title": "About me",
    "section": "My blog",
    "text": "My blog\n 1. Lecture\n\nR for Data Science\nSpecial Topics in Data Visualization\nIntroduction to Python\nSpecial Topics in Big Data Analysis\nSpecial Topics in Machine Learning\n\n 2. Tableau\n\nTableau Practice\n\n 3. DX\n\nDX Consultant Education\n\n 4. Study\n\nISLP Study\nAlgorithm Study\n\n 5. Projects\n\nMini Project 1 : 행동 데이터 분류 AI 모델링",
    "crumbs": [
      "**About me**"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Portfolio",
    "section": "",
    "text": "links\n\nlectureStudymini projectsbig projectspublications\n\n\n1 R for Data Science\n2 Special Topics in Data Visualization\n3 Introduction to Python\n4 Special Topics in Big Data Analysis\n5 Special Topics in Machine Learning\n6 Tableau Practice\n7 DX Consultant Education\n\n\n1 ISLP Study\n2 Algorithm Study\n\n\n1 mini project1 : Fine Watch 계단오르기 행동감지 모델링링\n\n\n\nISLP Study\nAlgorithm Study\n\n\n\n1 데이터 분석을 통한 지역별 고령친화도 시각화\n\n김영선, 강민구, 이강철 등 | 문화융복합아카이빙연구소 | 2021. 10 | 기록관리/보존\n\n2 핵심어 추출 및 데이터 증강기법을 이용한 텍스트 분류 모델 성능 개선\n\n이강철, 안정용 | 한국자료분석학회 | 한국자료분석학회 | 2022. 10 | 통계학\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nSep 20, 2023\n\n\n00. EDA & Modeling\n\n\nGC \n\n\n\n\nSep 20, 2023\n\n\n01. model tuning & save\n\n\nGC \n\n\n\n\nJul 31, 2023\n\n\n00. quarto blog\n\n\nGC \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html",
    "title": "00. EDA & Modeling",
    "section": "",
    "text": "1 Fine Watch의 행동 데이터 분류 AI 모델링 요청\n2 출시될 시제품에서 수집한 데이터를 바탕으로 6가지 행동 검토 후 계단오르기를 분류할 수 있는 AI 모델 생성 및 중요도 상위 Feature 선별\n\n6가지 행동 패턴 : STANDING, SITTING, LAYING, WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS\n\n3 데이터 설명\n\nFine Watch 23 시제품에서 수집한 데이터\n가속도 센서 데이터 : 일직선으로 움직이는 물체의 선형가속도를 측정하는 센서 데이터\n자이로스코프 센서 데이터 : 회전하는 물체의 각속도를 측정하는 센서 데이터",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "00. EDA & Modeling"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#feature-데이터-로드",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#feature-데이터-로드",
    "title": "00. EDA & Modeling",
    "section": "(1) feature 데이터 로드",
    "text": "(1) feature 데이터 로드\n\nfeatures = pd.read_csv(\"f.csv\")\nfeatures.head()\n\n\n\n\n\n\n\n\nsensor\nagg\naxis\nfeature_name\n\n\n\n\n0\ntBodyAcc\nmean()\nX\ntBodyAcc-mean()-X\n\n\n1\ntBodyAcc\nmean()\nY\ntBodyAcc-mean()-Y\n\n\n2\ntBodyAcc\nmean()\nZ\ntBodyAcc-mean()-Z\n\n\n3\ntBodyAcc\nstd()\nX\ntBodyAcc-std()-X\n\n\n4\ntBodyAcc\nstd()\nY\ntBodyAcc-std()-Y",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "00. EDA & Modeling"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#고유값-확인",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#고유값-확인",
    "title": "00. EDA & Modeling",
    "section": "(2) 고유값 확인",
    "text": "(2) 고유값 확인\n\nfeatures.sensor.value_counts()\n\nsensor\nfBodyGyro               79\nfBodyAcc                79\nfBodyAccJerk            79\ntBodyAcc                40\ntBodyAccJerk            40\ntBodyGyro               40\ntBodyGyroJerk           40\ntGravityAcc             40\nfBodyBodyGyroJerkMag    13\nfBodyBodyGyroMag        13\nfBodyBodyAccJerkMag     13\nfBodyAccMag             13\ntBodyGyroJerkMag        13\ntBodyGyroMag            13\ntBodyAccJerkMag         13\ntGravityAccMag          13\ntBodyAccMag             13\nangle                    7\nName: count, dtype: int64\n\n\n\nfeatures[\"feature_name\"].value_counts()\n\nfeature_name\nfBodyGyro-bandsEnergy()-25,32    3\nfBodyGyro-bandsEnergy()-49,56    3\nfBodyGyro-bandsEnergy()-25,48    3\nfBodyGyro-bandsEnergy()-1,24     3\nfBodyGyro-bandsEnergy()-49,64    3\n                                ..\ntBodyGyroJerk-min()-X            1\ntBodyGyroJerk-max()-Z            1\ntBodyGyroJerk-max()-Y            1\ntBodyGyroJerk-max()-X            1\nangle(Z,gravityMean)             1\nName: count, Length: 533, dtype: int64\n\n\n\nfeatures[\"agg\"].value_counts()\n\nagg\nbandsEnergy()        126\narCoeff()             60\nmean()                33\nmad()                 33\nmax()                 33\nmin()                 33\nenergy()              33\niqr()                 33\nentropy()             33\nstd()                 33\nsma()                 17\ncorrelation()         15\nmeanFreq()            13\nkurtosis()            13\nskewness()            13\nmaxInds               13\narCoeff()3             5\narCoeff()4             5\narCoeff()2             5\narCoeff()1             5\ntBodyAccMean           1\ntBodyAccJerkMean       1\ntBodyGyroMean          1\ntBodyGyroJerkMean      1\nX                      1\nY                      1\nZ                      1\nName: count, dtype: int64\n\n\n\nfeatures[\"axis\"].value_counts()\n\naxis\nX              76\nY              76\nZ              76\ngravityMean     6\nX,2             5\n               ..\n25,32.1         2\n17,24.1         2\n1,8.1           2\n9,16.1          2\ngravity         1\nName: count, Length: 62, dtype: int64",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "00. EDA & Modeling"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#데이터-셋-나누기",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#데이터-셋-나누기",
    "title": "00. EDA & Modeling",
    "section": "(0) 데이터 셋 나누기",
    "text": "(0) 데이터 셋 나누기\n\ny = data[target]\nx = data.drop(target, axis = 1)\n\nx_train, x_val, y_train, y_val = train_test_split(x,y, test_size = 0.3, random_state = 2023)      \n\n- 각 모델의 비교를 위한 데이터 프레임 생성\n\nmodel_name = []\nvalid_data = []\naccuracy_score = []\nF1_score = []\nresult = pd.DataFrame([model_name,valid_data,accuracy_score,F1_score]).T\nresult.columns = ['model_name', 'valid_data', 'accuracy_score', 'F1_score']\nresult\n\n\n\n\n\n\n\n\nmodel_name\nvalid_data\naccuracy_score\nF1_score",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "00. EDA & Modeling"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#svm",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#svm",
    "title": "00. EDA & Modeling",
    "section": "(1) SVM",
    "text": "(1) SVM\n\nfrom sklearn.svm import SVC\n\n\nsvc_model = SVC(random_state  = 2023)\nsvc_model.fit(x_train, y_train)\nsvc_pred = svc_model.predict(x_val)\n#svc_pred",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "00. EDA & Modeling"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#logistic",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#logistic",
    "title": "00. EDA & Modeling",
    "section": "(2) Logistic",
    "text": "(2) Logistic\n\nfrom sklearn.linear_model import LogisticRegression\n\nlr_model = LogisticRegression(random_state=2023)\nlr_model.fit(x_train, y_train)\nlr_pred = lr_model.predict(x_val)\n\nC:\\Users\\rkdcj\\anaconda3\\envs\\dx\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning:\n\nlbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n\n\n\n\nresult.loc[1,:] = ['lr', 'train', np.mean(y_val == lr_pred), f1_score(y_val,lr_pred, average = \"macro\")]\nresult\n\n\n\n\n\n\n\n\nmodel_name\nvalid_data\naccuracy_score\nF1_score\n\n\n\n\n1\nlr\ntrain\n0.984136\n0.985601",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "00. EDA & Modeling"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#knn",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#knn",
    "title": "00. EDA & Modeling",
    "section": "(3) KNN",
    "text": "(3) KNN\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\n\nknn_model = KNeighborsClassifier(n_neighbors=3)\nknn_model.fit(x_train, y_train)\nknn_pred = knn_model.predict(x_val)\n\n\nresult.loc[2] = [\"knn\",\"train\",np.mean(knn_pred == y_val), f1_score(y_val,knn_pred, average = \"macro\")] \nresult\n\n\n\n\n\n\n\n\nmodel_name\nvalid_data\naccuracy_score\nF1_score\n\n\n\n\n1\nlr\ntrain\n0.984136\n0.985601\n\n\n2\nknn\ntrain\n0.954674\n0.958345",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "00. EDA & Modeling"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#gbm",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#gbm",
    "title": "00. EDA & Modeling",
    "section": "(4) GBM",
    "text": "(4) GBM\n\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n\ngbc_model = GradientBoostingClassifier(random_state = 2023)\ngbc_model.fit(x_train,y_train)\ngbc_pred = gbc_model.predict(x_val)\n\n\nresult.loc[3] = [\"gbc\",\"train\",np.mean(gbc_pred == y_val), f1_score(y_val, gbc_pred, average = \"macro\")]\nresult\n\n\n\n\n\n\n\n\nmodel_name\nvalid_data\naccuracy_score\nF1_score\n\n\n\n\n1\nlr\ntrain\n0.984136\n0.985601\n\n\n2\nknn\ntrain\n0.954674\n0.958345\n\n\n3\ngbc\ntrain\n0.981870\n0.983141",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "00. EDA & Modeling"
    ]
  },
  {
    "objectID": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#xgb",
    "href": "posts/mini projects/Fine Watch/2023-09-20-00 . EDA , modeling.html#xgb",
    "title": "00. EDA & Modeling",
    "section": "(5) XGB",
    "text": "(5) XGB\n\nfrom xgboost import XGBClassifier\n\ndic = {'LAYING' : 2,\n 'SITTING' : 1,\n 'STANDING' : 0,\n 'WALKING' : 3,\n 'WALKING_DOWNSTAIRS' : 4,\n 'WALKING_UPSTAIRS': 5}\n\ny_train_map = [dic[i] for i in y_train]\ny_val_map =  [dic[i] for i in y_val]                                                                     \n\n\nxgb_model = XGBClassifier(learning_rate=0.2, max_depth=2, random_state=2023)\n\nxgb_model.fit(x_train,y_train_map)\n\nxgb_pred = xgb_model.predict(x_val)\n\nresult.loc[5] =  [\"xgb\", \"train\", np.mean(xgb_pred == y_val_map), f1_score(y_val_map, xgb_pred, average = \"macro\")]\nresult\n\n\n\n\n\n\n\n\nmodel_name\nvalid_data\naccuracy_score\nF1_score\n\n\n\n\n1\nlr\ntrain\n0.984136\n0.985601\n\n\n2\nknn\ntrain\n0.954674\n0.958345\n\n\n3\ngbc\ntrain\n0.981870\n0.983141\n\n\n5\nxgb\ntrain\n0.990368\n0.991178",
    "crumbs": [
      "Posts",
      "mini projects",
      "Fine Watch",
      "00. EDA & Modeling"
    ]
  }
]