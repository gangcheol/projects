{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3585aac6-76d8-4b98-a092-784f174d6568",
   "metadata": {},
   "source": [
    "---\n",
    "title : \"03. model theory\"\n",
    "author : \"GC\"\n",
    "date : \"01/01/24\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788311ed-7b16-4239-b667-db31d4854f5d",
   "metadata": {},
   "source": [
    "# abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e3b80d-b7ec-4dff-9a8c-c2a65d317668",
   "metadata": {},
   "source": [
    "`-` pythoch의 torchvision에서 제공하는 모델 중  `mc3_18` 이라는 모델을 이번 빅프에서 사용했는데 해당 모델을 정리할 필요가 있음. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9921e4-0d2e-42ba-8d5d-d53891fdcbec",
   "metadata": {},
   "source": [
    "* 초록을 읽어보니 `2D CNN`에서보다 `3D CNN`을 기반으로 만들어진 모델이 더욱 성능이 정확도가 높은 것을 보여주었음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af363435-6139-45cc-93bf-ec3f0b341e22",
   "metadata": {},
   "source": [
    "* 그리고 `3D Conv Filter`를  `spatial(공간적)`인 특징과 `Temporal(시간적인)` 특징으로 분리하면 정확도가 크게 향상된다는 것을 보여줌."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22a3917-653e-425f-a255-ed01e11bcbbf",
   "metadata": {},
   "source": [
    "* 여튼 몇몇 데이터 셋을 이용해서 새로운 `spatiotemporal block R(2+1)D`인 `produces CNN`을 설계해서 우리가 사용한 모델을 만들어준 것임."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d81dbf7-cf88-4420-a602-9075f3eb82f2",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fa0d25-736e-470a-b06e-5bf7858ead4f",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b30964-b6bd-48e5-ab64-95663b76da22",
   "metadata": {},
   "source": [
    "`1` 기존의  2D CNN 기반 모델들`(ex. Alexnet, I3D)`은 비디오 분석에서 중요한 측면으로 간주되는 시간적 정보와 행동 패턴을 모델링 할 수 없다는 단점이 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b827bd6-f821-41e2-b1e9-af9dadbfc1c7",
   "metadata": {},
   "source": [
    "`2` 그래서 이러한 단점을 해결하기 위해 `mixed convolution(MC)`와 `spatiotemporal block R(2+1)D`을 이용함\n",
    "\n",
    "* **우리는 mixed convolution(MC)을 이용함**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b0ea4b-1566-4989-94e0-f5b1304bf3ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "`3` mixed convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cd09ad-a5db-4f57-a655-8dfc34b71aa4",
   "metadata": {},
   "source": [
    "* 네트워크의 초기 몇개의 layer에서만 3D conv를 사용하고 top layer에서 2D conv를 사용\n",
    "\n",
    "* 해당 설계의 근거는 동작에 대한 모델링의 경우 3D conv를 통해 구현될 수 있는 low/mid-level 작업임\n",
    "\n",
    "* 이러한 mid-levle에서 산출된 `행동 features(frame을 말하는것 같음)`에 대한 공간적 추론은 정확한 행동 인식으로 이어진다는 것임."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703fd169-10c6-482a-ab5e-fac6a4c3c9e9",
   "metadata": {},
   "source": [
    "`4` spatiotemporal block R(2+1)D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8d16ac-260e-4b81-80a7-3fcc011552ee",
   "metadata": {},
   "source": [
    "* 3D conv를 `2D saptial convolution`과 `1D temporal convolution`으로 분해하는 것을 뜻함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48409f8-4c00-493a-88c6-a63f7618e6a2",
   "metadata": {},
   "source": [
    "* 장점 1 : 3D conv 안에서 분해된 공간적인 특성과 시간적인 특성 사이에 추가적인 비선형계층을 추가해 복잡한 모델링을 할 수 있음\n",
    "\n",
    "    * 이는 만약 full 3D conv가 10개의 파라미터를 사용했다면, 제안한 모델에서는 두 배 가량 복잡한 모델을 만들 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7c876b-5fad-4756-ae79-fe1d0c061989",
   "metadata": {},
   "source": [
    "* 장점 2 :  저런 시간적, 공간적 요소를 분해함에 있어 최적화를 촉진하고 실제로 train loss와 test loss를 줄일 수 있다는 것인데... (잠재적 이점이므로 skip하자.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c30e75-5b3f-427a-9b87-043634c48948",
   "metadata": {},
   "source": [
    "`5` 머여튼 그래서 해당 논문에서 제안한 모델이 성능이 좋았단 것임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0354c76-8aa8-4a77-aa5c-bf674b9b0c99",
   "metadata": {},
   "source": [
    "# MC3 모델이란 그래서?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c0249f-e0a6-4f0f-8b2a-e2db0579a458",
   "metadata": {},
   "source": [
    "<center><img src = \"m3c.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0a07cb-c4ee-4662-a093-4fe2059d45d8",
   "metadata": {},
   "source": [
    "`-` `resnet` 모델과 `mixed convolutions`을 결합한 모델이라고 한다..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2af8eb0-85c6-416b-adde-2541dbef6dcf",
   "metadata": {},
   "source": [
    "* 이 부분은 나중에 그림 어케 그릴지 생각...`(그냥 resnet + mixed conv 해서 mc3 모델 사용했다고?)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792bd3e5-cac0-4fcf-80fd-0457c2888228",
   "metadata": {},
   "source": [
    "# reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7066551b-2a14-44a8-a183-195111b9a83b",
   "metadata": {},
   "source": [
    "[1] [Du Tran, Heng Wang, Lorenzo Torresani, Jamie Ray, Yann LeCun, Manohar Paluri (2018). A Closer Look at Sptiotemporal Convolutions for Action Recognition](https://arxiv.org/pdf/1711.11248v3.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
